{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmZ7TT_ZX1QF",
    "outputId": "71cb8974-92ab-4c8d-9c0b-8e63c051f832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Multimodal-Sentiment-Analysis-with-Sarcasm-Detection' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/VivianZhao12/Multimodal-Sentiment-Analysis-with-Sarcasm-Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YklIVwNqY2TS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sicilywang/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import scikitplot as skplt\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC  # Importing Support Vector Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # For oversampling\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization, Layer, Softmax, Activation, Conv1D, MaxPooling1D, Flatten, LSTM, InputLayer\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou6odKSvaI7S",
    "outputId": "0234a9f3-73e8-4d60-de9c-e875a8989086"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
       "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'PCA_MFCC_1',\n",
       "       'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4', 'PCA_MFCC_5', 'PCA_MFCC_6',\n",
       "       'PCA_MFCC_7', 'PCA_MFCC_8', 'sentence_level_similarity_emotion',\n",
       "       'sentence_level_similarity_word', 'exclamation', 'PCA_W2V_1',\n",
       "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
       "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
       "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
       "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
       "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
       "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
       "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
       "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
       "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
       "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50', 'PCA_W2V_51',\n",
       "       'PCA_W2V_52', 'PCA_W2V_53', 'PCA_W2V_54', 'PCA_W2V_55', 'PCA_W2V_56',\n",
       "       'PCA_W2V_57', 'PCA_W2V_58', 'PCA_W2V_59', 'PCA_W2V_60', 'energy',\n",
       "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
       "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
       "       'mfccs_12', 'mfccs_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sar = pd.read_csv('../datasets/sarcasm_final.csv')\n",
    "df_sar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s-Y7O8-qaK-X"
   },
   "outputs": [],
   "source": [
    "# Define all the feature columns (text + audio features)\n",
    "all_feature_columns = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of text features for the text-only model\n",
    "feature_columns_text = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of audio features for the text-only model\n",
    "feature_columns_audio = [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nSSkvQaIaN2a"
   },
   "outputs": [],
   "source": [
    "# target prediction\n",
    "target_column = 'sarcasm_label'\n",
    "\n",
    "# Prepare the feature set and target column for both models\n",
    "X_all = df_sar[all_feature_columns]\n",
    "y = df_sar[target_column]\n",
    "\n",
    "# Function to scale, split, and apply SMOTE\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test\n",
    "\n",
    "# --- Text-Only Model ---\n",
    "X_text = df_sar[feature_columns_text]\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = preprocess_data(X_text, y)\n",
    "\n",
    "# --- Audio-Only Model --- this is for following hybrid model\n",
    "X_audio = df_sar[feature_columns_audio]\n",
    "X_train_audio, X_test_audio, y_train_audio, y_test_audio = preprocess_data(X_audio, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tBrkqKBTaQTW"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with text features\n",
    "logistic_model_text = LogisticRegression(max_iter=500, random_state=42)\n",
    "logistic_model_text.fit(X_train_text, y_train_text)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_text = logistic_model_text.predict(X_test_text)\n",
    "\n",
    "# --- Combined Model (Text + Audio Features) ---\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)\n",
    "\n",
    "# Logistic Regression with both text and audio features\n",
    "logistic_model_combined = LogisticRegression(max_iter=500, random_state=42)\n",
    "logistic_model_combined.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_combined = logistic_model_combined.predict(X_test_combined)\n",
    "y_pred_logistic_proba = logistic_model_combined.decision_function(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a9jo2MlZdIlX"
   },
   "outputs": [],
   "source": [
    "# Evaluation Results (Text-Only Model)\n",
    "accuracy_text = accuracy_score(y_test_text, y_pred_text)\n",
    "cm_text = confusion_matrix(y_test_text, y_pred_text)\n",
    "cr_text = classification_report(y_test_text, y_pred_text, output_dict=True)\n",
    "\n",
    "# Evaluation Results (Combined Model)\n",
    "accuracy_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
    "cm_combined = confusion_matrix(y_test_combined, y_pred_combined)\n",
    "cr_combined = classification_report(y_test_combined, y_pred_combined, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31wMFz4rdOiD",
    "outputId": "f7913b40-798a-4569-fc38-7be26355bcfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.318500\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_text.columns contains the correct feature names\n",
    "feature_names = ['Intercept'] + list(X_all.columns)\n",
    "\n",
    "# Add an intercept to the combined dataset\n",
    "X_train_combined_with_intercept = sm.add_constant(X_train_combined)\n",
    "\n",
    "# Fit the logistic regression model using statsmodels\n",
    "logit_model = sm.Logit(y_train_combined, X_train_combined_with_intercept)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Convert the result summary to a DataFrame and replace the index with feature names\n",
    "summary_table = result.summary2().tables[1]  # Get the coefficient table\n",
    "summary_table.index = feature_names  # Replace generic 'x1', 'x2', ... with actual names\n",
    "\n",
    "sorted_summary = summary_table.sort_values(by='P>|z|')\n",
    "\n",
    "# Identify significant features based on p-value\n",
    "significant_features = summary_table[summary_table['P>|z|'] < 0.01]\n",
    "\n",
    "# Sort significant features by the absolute value of their coefficients\n",
    "significant_features_sorted = significant_features.reindex(\n",
    "    significant_features['Coef.'].abs().sort_values(ascending=False).index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "604qfkNTdT6c",
    "outputId": "09c9e3f4-8908-4732-9e65-8ad92eacc17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine (SVM) Results:\n",
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85        38\n",
      "           1       0.59      0.71      0.65        14\n",
      "\n",
      "    accuracy                           0.79        52\n",
      "   macro avg       0.74      0.77      0.75        52\n",
      "weighted avg       0.81      0.79      0.79        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM) Model\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict with SVM\n",
    "y_pred_svm = svm_model.predict(X_test_combined)\n",
    "# Calculate probabilities for SVM\n",
    "y_pred_svm_proba = svm_model.decision_function(X_test_combined)  # For SVM, use decision_function for Precision-Recall\n",
    "\n",
    "\n",
    "# Evaluate SVM Model\n",
    "print(\"\\nSupport Vector Machine (SVM) Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_svm):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-U3spqQdYGE",
    "outputId": "fb5a2cbb-3c6e-4e97-bac2-38b751f8d362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.77\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83        38\n",
      "           1       0.55      0.79      0.65        14\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.73      0.77      0.74        52\n",
      "weighted avg       0.81      0.77      0.78        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_combined, y_train_combined)\n",
    "y_pred_nb_proba = nb_model.predict(X_test_combined)\n",
    "\n",
    "# Evaluate Naive Bayes Model\n",
    "print(\"\\nNaive Bayes Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_nb_proba):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_nb_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7dbX8OudbnD",
    "outputId": "d69a23f8-c51b-457e-ed52-c632a75ef457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.81\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        38\n",
      "           1       0.67      0.57      0.62        14\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.76      0.73      0.74        52\n",
      "weighted avg       0.80      0.81      0.80        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "clf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_clf = clf_model.predict(X_test_combined)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy_clf = accuracy_score(y_test_combined, y_pred_clf)\n",
    "\n",
    "# Generating a classification report\n",
    "class_report = classification_report(y_test_combined, y_pred_clf)\n",
    "\n",
    "# Printing out the results\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_clf:.2f}\")\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dEcG1bldhrT",
    "outputId": "4c408d50-b9da-4732-8240-426bd9b79ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.77\n",
      "SVM Accuracy: 0.79\n",
      "Naive Bayes Accuracy: 0.77\n",
      "Random Forest Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracies for each model\n",
    "accuracy_logistic = logistic_model_combined.score(X_test_combined, y_test_combined)\n",
    "accuracy_svm = svm_model.score(X_test_combined, y_test_combined)\n",
    "accuracy_nb = nb_model.score(X_test_combined, y_test_combined)\n",
    "\n",
    "# Print accuracy values\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.2f}\")\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
    "print(f\"Random Forest Accuracy: {accuracy_clf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BqTuKbQedjKz"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Precision-Recall\n",
    "precision_logistic, recall_logistic, _ = precision_recall_curve(y_test_combined, y_pred_logistic_proba)\n",
    "pr_auc_logistic = auc(recall_logistic, precision_logistic)\n",
    "\n",
    "# SVM Precision-Recall\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_test_combined, y_pred_svm_proba)\n",
    "pr_auc_svm = auc(recall_svm, precision_svm)\n",
    "\n",
    "# Naive Bayes Precision-Recall\n",
    "precision_nb, recall_nb, _ = precision_recall_curve(y_test_combined, y_pred_nb_proba)\n",
    "pr_auc_nb = auc(recall_nb, precision_nb)\n",
    "\n",
    "# Assuming clf_rf is your trained Random Forest classifier\n",
    "y_pred_rf_proba = clf_model.predict_proba(X_test_combined)[:, 1]\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test_combined, y_pred_rf_proba)\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)\n",
    "\n",
    "# Compute ROC curves and AUC scores\n",
    "fpr_logistic, tpr_logistic, _ = roc_curve(y_test_combined, y_pred_logistic_proba)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test_combined, y_pred_nb_proba)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test_combined, y_pred_svm_proba)\n",
    "\n",
    "auc_logistic = roc_auc_score(y_test_combined, y_pred_logistic_proba)\n",
    "auc_svm = roc_auc_score(y_test_combined, y_pred_svm_proba)\n",
    "auc_nb = roc_auc_score(y_test_combined, y_pred_nb_proba)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_combined, y_pred_rf_proba)\n",
    "auc_rf = roc_auc_score(y_test_combined, y_pred_rf_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAofh4z4dn77",
    "outputId": "f2688be3-785a-4507-c321-d6e873f5febf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7028 - accuracy: 0.5625 - val_loss: 0.7427 - val_accuracy: 0.3500\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6167 - val_loss: 0.7474 - val_accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6542 - val_loss: 0.7224 - val_accuracy: 0.3667\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6625 - val_loss: 0.6994 - val_accuracy: 0.5500\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6542 - val_loss: 0.6721 - val_accuracy: 0.6167\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7000 - val_loss: 0.6318 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7167 - val_loss: 0.6096 - val_accuracy: 0.7833\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7292 - val_loss: 0.5797 - val_accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8000 - val_loss: 0.5471 - val_accuracy: 0.8667\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7917 - val_loss: 0.5064 - val_accuracy: 0.8833\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7750 - val_loss: 0.4868 - val_accuracy: 0.8833\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7667 - val_loss: 0.4568 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7750 - val_loss: 0.4390 - val_accuracy: 0.9000\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8167 - val_loss: 0.4286 - val_accuracy: 0.9000\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8417 - val_loss: 0.4130 - val_accuracy: 0.9000\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.7958 - val_loss: 0.3922 - val_accuracy: 0.9000\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8292 - val_loss: 0.3913 - val_accuracy: 0.9000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8250 - val_loss: 0.3817 - val_accuracy: 0.9000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8292 - val_loss: 0.3767 - val_accuracy: 0.9167\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8542 - val_loss: 0.3607 - val_accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8250 - val_loss: 0.3483 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8417 - val_loss: 0.3404 - val_accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8208 - val_loss: 0.3195 - val_accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8708 - val_loss: 0.3114 - val_accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8792 - val_loss: 0.3014 - val_accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8292 - val_loss: 0.2952 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8500 - val_loss: 0.2846 - val_accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8500 - val_loss: 0.2727 - val_accuracy: 0.9167\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.8625 - val_loss: 0.2714 - val_accuracy: 0.9167\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8625 - val_loss: 0.2800 - val_accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8667 - val_loss: 0.2745 - val_accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8625 - val_loss: 0.2669 - val_accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8708 - val_loss: 0.2649 - val_accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8958 - val_loss: 0.2566 - val_accuracy: 0.9167\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8500 - val_loss: 0.2479 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8667 - val_loss: 0.2455 - val_accuracy: 0.9167\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8792 - val_loss: 0.2448 - val_accuracy: 0.9167\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.8917 - val_loss: 0.2511 - val_accuracy: 0.9167\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9042 - val_loss: 0.2480 - val_accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8750 - val_loss: 0.2401 - val_accuracy: 0.9167\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8750 - val_loss: 0.2275 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8917 - val_loss: 0.2199 - val_accuracy: 0.9167\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.9042 - val_loss: 0.2261 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8833 - val_loss: 0.2275 - val_accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8792 - val_loss: 0.2232 - val_accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8917 - val_loss: 0.2209 - val_accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.8958 - val_loss: 0.2092 - val_accuracy: 0.9167\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8875 - val_loss: 0.1945 - val_accuracy: 0.9167\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8917 - val_loss: 0.1924 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9000 - val_loss: 0.1896 - val_accuracy: 0.9167\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7885\n",
      "FCNN Accuracy: 0.7884615659713745\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Ensuring the same random seed is used every time before any layer weights are initialized\n",
    "# Build a full connect neural network\n",
    "model_FCNN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_FCNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_FCNN.fit(X_train_combined, y_train_combined, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "fcnn_loss, fcnn_accuracy = model_FCNN.evaluate(X_test_combined, y_test_combined)\n",
    "print(f'FCNN Accuracy: {fcnn_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f_an5vJ9faB8"
   },
   "outputs": [],
   "source": [
    "model_FCNN.save(\"model_FCNN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14OYeL6od-in",
    "outputId": "69075722-37d3-4790-b556-257d9c416f75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 1.6770 - accuracy: 0.5417 - val_loss: 1.5980 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.5622 - accuracy: 0.6333 - val_loss: 1.5440 - val_accuracy: 0.7667\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4832 - accuracy: 0.6667 - val_loss: 1.4917 - val_accuracy: 0.8000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3554 - accuracy: 0.7792 - val_loss: 1.4372 - val_accuracy: 0.8333\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3600 - accuracy: 0.7417 - val_loss: 1.3852 - val_accuracy: 0.8667\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3163 - accuracy: 0.7833 - val_loss: 1.3280 - val_accuracy: 0.8667\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2524 - accuracy: 0.8000 - val_loss: 1.2801 - val_accuracy: 0.8833\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1662 - accuracy: 0.8250 - val_loss: 1.2280 - val_accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1203 - accuracy: 0.8583 - val_loss: 1.1749 - val_accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1063 - accuracy: 0.8625 - val_loss: 1.1214 - val_accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.0880 - accuracy: 0.8625 - val_loss: 1.0813 - val_accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0532 - accuracy: 0.8417 - val_loss: 1.0403 - val_accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0380 - accuracy: 0.8500 - val_loss: 1.0034 - val_accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.8250 - val_loss: 0.9774 - val_accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9996 - accuracy: 0.8208 - val_loss: 0.9485 - val_accuracy: 0.9167\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9471 - accuracy: 0.8542 - val_loss: 0.9147 - val_accuracy: 0.9167\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9351 - accuracy: 0.8333 - val_loss: 0.8915 - val_accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8977 - accuracy: 0.8583 - val_loss: 0.8669 - val_accuracy: 0.9167\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.8750 - val_loss: 0.8430 - val_accuracy: 0.9167\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8288 - accuracy: 0.8708 - val_loss: 0.8186 - val_accuracy: 0.9167\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8536 - accuracy: 0.8500 - val_loss: 0.7945 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7833 - accuracy: 0.8875 - val_loss: 0.7782 - val_accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.9083 - val_loss: 0.7552 - val_accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7296 - accuracy: 0.9125 - val_loss: 0.7336 - val_accuracy: 0.9167\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.8833 - val_loss: 0.7154 - val_accuracy: 0.9167\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.8667 - val_loss: 0.7001 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.9000 - val_loss: 0.6794 - val_accuracy: 0.9333\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.9042 - val_loss: 0.6615 - val_accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.9083 - val_loss: 0.6451 - val_accuracy: 0.9333\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.8875 - val_loss: 0.6332 - val_accuracy: 0.9333\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.8625 - val_loss: 0.6203 - val_accuracy: 0.9333\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8958 - val_loss: 0.6126 - val_accuracy: 0.9333\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.9125 - val_loss: 0.6015 - val_accuracy: 0.9333\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.9292 - val_loss: 0.5869 - val_accuracy: 0.9333\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.9250 - val_loss: 0.5755 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.9250 - val_loss: 0.5655 - val_accuracy: 0.9333\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.9083 - val_loss: 0.5546 - val_accuracy: 0.9333\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.9000 - val_loss: 0.5461 - val_accuracy: 0.9333\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.9042 - val_loss: 0.5398 - val_accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.9083 - val_loss: 0.5319 - val_accuracy: 0.9333\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.9125 - val_loss: 0.5147 - val_accuracy: 0.9500\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.9208 - val_loss: 0.5052 - val_accuracy: 0.9500\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.9417 - val_loss: 0.5037 - val_accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.9333 - val_loss: 0.4922 - val_accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.9333 - val_loss: 0.4841 - val_accuracy: 0.9500\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.9125 - val_loss: 0.4721 - val_accuracy: 0.9500\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.9208 - val_loss: 0.4543 - val_accuracy: 0.9500\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.9292 - val_loss: 0.4375 - val_accuracy: 0.9500\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.9125 - val_loss: 0.4236 - val_accuracy: 0.9500\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.9375 - val_loss: 0.4107 - val_accuracy: 0.9667\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.8077\n",
      "Enhanced FCNN Model Accuracy: 0.807692289352417\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Build a more robust fully connected neural network\n",
    "model_ehFCNN = Sequential([\n",
    "    InputLayer(input_shape=(X_train_combined.shape[1],)),\n",
    "\n",
    "    Dense(64, kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Optimizer with a learning rate schedule\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model_ehFCNN.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and saving the best model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model with validation split and callbacks\n",
    "history = model_ehFCNN.fit(\n",
    "    X_train_combined,\n",
    "    y_train_combined,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "fcnn_loss, fcnn_accuracy = model_ehFCNN.evaluate(X_test_combined, y_test_combined)\n",
    "print(f'Enhanced FCNN Model Accuracy: {fcnn_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxM5v5GkYCZT",
    "outputId": "d3cbe829-8528-4d57-9192-67491bb2ac88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 2.3218 - accuracy: 0.5667 - val_loss: 2.0001 - val_accuracy: 0.7115\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.8954 - accuracy: 0.7800 - val_loss: 1.8796 - val_accuracy: 0.7885\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7625 - accuracy: 0.8067 - val_loss: 1.7990 - val_accuracy: 0.8077\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.6307 - accuracy: 0.8300 - val_loss: 1.7287 - val_accuracy: 0.8077\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5967 - accuracy: 0.8467 - val_loss: 1.6713 - val_accuracy: 0.8269\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5287 - accuracy: 0.8333 - val_loss: 1.6163 - val_accuracy: 0.8077\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3967 - accuracy: 0.8833 - val_loss: 1.5673 - val_accuracy: 0.8077\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3384 - accuracy: 0.8967 - val_loss: 1.5213 - val_accuracy: 0.8077\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3106 - accuracy: 0.8700 - val_loss: 1.4795 - val_accuracy: 0.7885\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2498 - accuracy: 0.9100 - val_loss: 1.4391 - val_accuracy: 0.7885\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1950 - accuracy: 0.9100 - val_loss: 1.3946 - val_accuracy: 0.7692\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1487 - accuracy: 0.9133 - val_loss: 1.3552 - val_accuracy: 0.7885\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1101 - accuracy: 0.9067 - val_loss: 1.3260 - val_accuracy: 0.7885\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0854 - accuracy: 0.9333 - val_loss: 1.2877 - val_accuracy: 0.7885\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.9400 - val_loss: 1.2512 - val_accuracy: 0.7885\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0021 - accuracy: 0.9300 - val_loss: 1.2239 - val_accuracy: 0.7885\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9525 - accuracy: 0.9467 - val_loss: 1.1952 - val_accuracy: 0.7692\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9218 - accuracy: 0.9467 - val_loss: 1.1633 - val_accuracy: 0.7692\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9071 - accuracy: 0.9400 - val_loss: 1.1364 - val_accuracy: 0.7692\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8648 - accuracy: 0.9600 - val_loss: 1.1180 - val_accuracy: 0.8077\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8406 - accuracy: 0.9400 - val_loss: 1.0884 - val_accuracy: 0.8077\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8182 - accuracy: 0.9400 - val_loss: 1.0600 - val_accuracy: 0.8077\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7858 - accuracy: 0.9467 - val_loss: 1.0301 - val_accuracy: 0.7885\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7608 - accuracy: 0.9400 - val_loss: 1.0127 - val_accuracy: 0.8077\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.9667 - val_loss: 0.9893 - val_accuracy: 0.8077\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.9533 - val_loss: 0.9718 - val_accuracy: 0.8077\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.9567 - val_loss: 0.9588 - val_accuracy: 0.7885\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.9733 - val_loss: 0.9517 - val_accuracy: 0.7692\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.9633 - val_loss: 0.9415 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.9600 - val_loss: 0.9225 - val_accuracy: 0.8077\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.9767 - val_loss: 0.9127 - val_accuracy: 0.8269\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.9767 - val_loss: 0.9095 - val_accuracy: 0.8269\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.9767 - val_loss: 0.9015 - val_accuracy: 0.8269\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.9800 - val_loss: 0.8868 - val_accuracy: 0.7885\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.9767 - val_loss: 0.8784 - val_accuracy: 0.7692\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.9733 - val_loss: 0.8758 - val_accuracy: 0.8077\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.9700 - val_loss: 0.8492 - val_accuracy: 0.8269\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.9867 - val_loss: 0.8264 - val_accuracy: 0.8077\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.9833 - val_loss: 0.8141 - val_accuracy: 0.8269\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.9933 - val_loss: 0.8124 - val_accuracy: 0.8269\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.9733 - val_loss: 0.8089 - val_accuracy: 0.8269\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.9800 - val_loss: 0.8108 - val_accuracy: 0.8077\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.9700 - val_loss: 0.8139 - val_accuracy: 0.7885\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.9967 - val_loss: 0.8171 - val_accuracy: 0.8077\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.9767 - val_loss: 0.8020 - val_accuracy: 0.8077\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.9933 - val_loss: 0.7965 - val_accuracy: 0.8077\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.9967 - val_loss: 0.8026 - val_accuracy: 0.8077\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.9900 - val_loss: 0.7970 - val_accuracy: 0.8077\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.9800 - val_loss: 0.8075 - val_accuracy: 0.8269\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.9800 - val_loss: 0.7959 - val_accuracy: 0.8269\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7959 - accuracy: 0.8269\n",
      "Hybrid Model Accuracy: 0.8269230723381042\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "def build_hybrid_model(num_text_features, num_audio_features, regularization_rate=0.01):\n",
    "    # Text input branch\n",
    "    text_input = Input(shape=(num_text_features,), name='text_input')\n",
    "    text_hidden = Dense(128, activation='relu', kernel_regularizer=l2(regularization_rate))(text_input)\n",
    "    text_hidden = BatchNormalization()(text_hidden)\n",
    "    text_hidden = Dropout(0.3)(text_hidden)\n",
    "\n",
    "    # Audio input branch\n",
    "    audio_input = Input(shape=(num_audio_features,), name='audio_input')\n",
    "    audio_hidden = Dense(128, activation='relu', kernel_regularizer=l2(regularization_rate))(audio_input)\n",
    "    audio_hidden = BatchNormalization()(audio_hidden)\n",
    "    audio_hidden = Dropout(0.3)(audio_hidden)\n",
    "\n",
    "    # Concatenate both branches\n",
    "    concatenated = Concatenate()([text_hidden, audio_hidden])\n",
    "    concatenated = Dense(64, activation='relu', kernel_regularizer=l2(regularization_rate))(concatenated)\n",
    "    concatenated = Dropout(0.3)(concatenated)\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[text_input, audio_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model_ehhb = build_hybrid_model(num_text_features=11, num_audio_features=11)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Assume X_train_text, X_train_audio, y_train_combined are prepared\n",
    "# and similarly for X_test_text, X_test_audio, y_test_combined\n",
    "history = model_ehhb.fit(\n",
    "    [X_train_text, X_train_audio],\n",
    "    y_train_combined,\n",
    "    validation_data=([X_test_text, X_test_audio], y_test_combined),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "ehhb_accuracy = model_ehhb.evaluate([X_test_text, X_test_audio], y_test_combined)[1]\n",
    "print(\"Hybrid Model Accuracy:\", ehhb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2SlwIkV7fvn0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nViLzrlEgCNL"
   },
   "source": [
    "# Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVihZczIgJKs",
    "outputId": "f2b1543b-7263-4fad-8e85-8c1464042f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
       "       'sentence_level_similarity_emotion', 'sentence_level_similarity_word',\n",
       "       'exclamation', 'PCA_MFCC_1', 'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4',\n",
       "       'PCA_MFCC_5', 'PCA_MFCC_6', 'PCA_MFCC_7', 'PCA_MFCC_8', 'PCA_W2V_1',\n",
       "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
       "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
       "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
       "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
       "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
       "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
       "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
       "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
       "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
       "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50',\n",
       "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'energy',\n",
       "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
       "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
       "       'mfccs_12', 'mfccs_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen = pd.read_csv('/content/Multimodal-Sentiment-Analysis-with-Sarcasm-Detection/datasets/sentiment_final.csv')\n",
    "df_sen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oTjN5HIIbAmt"
   },
   "outputs": [],
   "source": [
    "# Define all the feature columns (text + audio features)\n",
    "all_feature_columns = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of text features for the text-only model\n",
    "feature_columns_text = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of audio features for the text-only model\n",
    "feature_columns_audio = [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VPWv-BGdbB27"
   },
   "outputs": [],
   "source": [
    "# target prediction\n",
    "target_column = 'sentiment_label'\n",
    "\n",
    "# Prepare the feature set and target column for both models\n",
    "X_all = df_sen[all_feature_columns]\n",
    "y = df_sen[target_column]\n",
    "\n",
    "# Function to scale, split, and apply SMOTE\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BLiwRcv5bV1T"
   },
   "outputs": [],
   "source": [
    "# --- Combined Model (Text + Audio Features) ---\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L7nfir-CbBuH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_FCNN_new = load_model(\"model_FCNN.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC4JJRxGpgip"
   },
   "source": [
    "## XG Boost without integrating Sarcasm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xLNqwhulKue",
    "outputId": "70d05864-491b-488f-85eb-193feb461310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.5428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create XGBoost DMatrix\n",
    "dtrain = xgb.DMatrix(X_train_combined, label=y_train_combined)\n",
    "dtest = xgb.DMatrix(X_test_combined, label=y_test_combined)\n",
    "\n",
    "# Set parameters\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 5,\n",
    "    \"n_estimators\": 10,\n",
    "    \"eta\": 0.1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model_xgb = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions\n",
    "preds = model_xgb.predict(dtest)\n",
    "predictions = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test_combined, predictions)\n",
    "print(f\"XGBoost Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iw-6Exnfj-k",
    "outputId": "da59ba77-b76c-47a6-920a-a1f0dcf26ef7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost Accuracy: 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_combined)\n",
    "\n",
    "accuracy = accuracy_score(y_test_combined, y_pred)\n",
    "print(f\"Optimized XGBoost Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep1HKF9rpiD4"
   },
   "source": [
    "## XG Boost with Sarcasm Model Integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDvfNbjcnIiv",
    "outputId": "dade2107-a400-497c-e81e-bcdf3c6f6f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated XGBoost Model with Sarcasm Accuracy: 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
    "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
    "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
    "# Add sarcasm predictions as a new feature\n",
    "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
    "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
    "\n",
    "dtrain = xgb.DMatrix(features_with_sarcasm_train, label=y_train_combined)\n",
    "dtest = xgb.DMatrix(features_with_sarcasm_test, label=y_test_combined)\n",
    "\n",
    "model_xgb_sarcasm = xgb.train(params, dtrain, num_boost_round=100)\n",
    "preds = model_xgb_sarcasm.predict(dtest)\n",
    "predictions = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "accuracy = accuracy_score(y_test_combined, predictions)\n",
    "print(f\"Updated XGBoost Model with Sarcasm Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd4cbC-dpsqX"
   },
   "source": [
    "## FFNN without Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGzO9nFLo7kJ",
    "outputId": "9acd0f5b-7028-4800-b722-9f754315332c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4331 - loss: 0.8909 - val_accuracy: 0.7188 - val_loss: 0.6463\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5283 - loss: 0.7803 - val_accuracy: 0.6250 - val_loss: 0.6629\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4800 - loss: 0.8008 - val_accuracy: 0.5938 - val_loss: 0.6822\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4814 - loss: 0.7425 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6555 - loss: 0.6299 - val_accuracy: 0.4375 - val_loss: 0.6928\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6791 - loss: 0.6430 - val_accuracy: 0.4375 - val_loss: 0.6929\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 0.7136 - val_accuracy: 0.4375 - val_loss: 0.7052\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5362 - loss: 0.6989 - val_accuracy: 0.4062 - val_loss: 0.7111\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.6686 - val_accuracy: 0.3750 - val_loss: 0.7179\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5769 - loss: 0.6470 - val_accuracy: 0.3125 - val_loss: 0.7168\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.6471 - val_accuracy: 0.3125 - val_loss: 0.7125\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4988 - loss: 0.6584 - val_accuracy: 0.3125 - val_loss: 0.6984\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5973 - loss: 0.6673 - val_accuracy: 0.3438 - val_loss: 0.6878\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5845 - loss: 0.6020 - val_accuracy: 0.3125 - val_loss: 0.6882\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.5870 - val_accuracy: 0.3125 - val_loss: 0.6895\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.6443 - val_accuracy: 0.3125 - val_loss: 0.6875\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5767 - loss: 0.6095 - val_accuracy: 0.3125 - val_loss: 0.6877\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 0.6307 - val_accuracy: 0.3125 - val_loss: 0.6861\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6466 - loss: 0.5932 - val_accuracy: 0.3438 - val_loss: 0.6851\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6690 - loss: 0.6020 - val_accuracy: 0.3438 - val_loss: 0.6770\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.5632 - val_accuracy: 0.4375 - val_loss: 0.6664\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.5798 - val_accuracy: 0.5000 - val_loss: 0.6581\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6187 - loss: 0.6403 - val_accuracy: 0.5312 - val_loss: 0.6479\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.5912 - val_accuracy: 0.5938 - val_loss: 0.6406\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 0.6469 - val_accuracy: 0.6250 - val_loss: 0.6411\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.5665 - val_accuracy: 0.6250 - val_loss: 0.6422\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.5473 - val_accuracy: 0.7188 - val_loss: 0.6300\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6579 - loss: 0.5708 - val_accuracy: 0.7812 - val_loss: 0.6254\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7047 - loss: 0.5662 - val_accuracy: 0.8125 - val_loss: 0.6189\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 0.5588 - val_accuracy: 0.8125 - val_loss: 0.6171\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.5249 - val_accuracy: 0.8125 - val_loss: 0.6132\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.5388 - val_accuracy: 0.7812 - val_loss: 0.6137\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.5619 - val_accuracy: 0.7812 - val_loss: 0.6218\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.5434 - val_accuracy: 0.7500 - val_loss: 0.6200\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.4784 - val_accuracy: 0.7500 - val_loss: 0.6194\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.5189 - val_accuracy: 0.7500 - val_loss: 0.6205\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5527 - val_accuracy: 0.7812 - val_loss: 0.6093\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6840 - loss: 0.5015 - val_accuracy: 0.7812 - val_loss: 0.6034\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5128 - val_accuracy: 0.7812 - val_loss: 0.5951\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.5429 - val_accuracy: 0.7812 - val_loss: 0.5879\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4979 - val_accuracy: 0.7812 - val_loss: 0.5783\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4710 - val_accuracy: 0.7812 - val_loss: 0.5786\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 0.4632 - val_accuracy: 0.8125 - val_loss: 0.5643\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.5377 - val_accuracy: 0.8125 - val_loss: 0.5596\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.5012 - val_accuracy: 0.8125 - val_loss: 0.5523\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6638 - loss: 0.5166 - val_accuracy: 0.8438 - val_loss: 0.5505\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6738 - loss: 0.5440 - val_accuracy: 0.8125 - val_loss: 0.5633\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4436 - val_accuracy: 0.7812 - val_loss: 0.5690\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.4826 - val_accuracy: 0.8125 - val_loss: 0.5705\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.5119 - val_accuracy: 0.8125 - val_loss: 0.5672\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4790 - val_accuracy: 0.8125 - val_loss: 0.5635\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.4645 - val_accuracy: 0.8125 - val_loss: 0.5602\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.4508 - val_accuracy: 0.8438 - val_loss: 0.5535\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.3974 - val_accuracy: 0.8438 - val_loss: 0.5421\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.4541 - val_accuracy: 0.8438 - val_loss: 0.5332\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.4389 - val_accuracy: 0.8438 - val_loss: 0.5227\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4803 - val_accuracy: 0.8438 - val_loss: 0.5177\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.4835 - val_accuracy: 0.8438 - val_loss: 0.5031\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.4237 - val_accuracy: 0.8438 - val_loss: 0.4919\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3768 - val_accuracy: 0.8438 - val_loss: 0.4916\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.4597 - val_accuracy: 0.8438 - val_loss: 0.5053\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.3984 - val_accuracy: 0.8438 - val_loss: 0.4958\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.5349 - val_accuracy: 0.8438 - val_loss: 0.4954\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4458 - val_accuracy: 0.8438 - val_loss: 0.4856\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.4391 - val_accuracy: 0.8438 - val_loss: 0.4809\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.4512 - val_accuracy: 0.8438 - val_loss: 0.4796\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.4956 - val_accuracy: 0.8438 - val_loss: 0.4799\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4150 - val_accuracy: 0.8438 - val_loss: 0.4727\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.3834 - val_accuracy: 0.8438 - val_loss: 0.4598\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.4176 - val_accuracy: 0.8438 - val_loss: 0.4681\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.3463 - val_accuracy: 0.8438 - val_loss: 0.4618\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.4057 - val_accuracy: 0.8438 - val_loss: 0.4620\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4117 - val_accuracy: 0.8438 - val_loss: 0.4633\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.3554 - val_accuracy: 0.8125 - val_loss: 0.4521\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.3503 - val_accuracy: 0.8125 - val_loss: 0.4518\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.4361 - val_accuracy: 0.8125 - val_loss: 0.4588\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4129 - val_accuracy: 0.8125 - val_loss: 0.4418\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8774 - loss: 0.3602 - val_accuracy: 0.8125 - val_loss: 0.4373\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4128 - val_accuracy: 0.8125 - val_loss: 0.4508\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.3293 - val_accuracy: 0.8125 - val_loss: 0.4580\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.3378 - val_accuracy: 0.8438 - val_loss: 0.4664\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9193 - loss: 0.2835 - val_accuracy: 0.8438 - val_loss: 0.4705\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.4143 - val_accuracy: 0.8125 - val_loss: 0.4581\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.3773 - val_accuracy: 0.8125 - val_loss: 0.4471\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.3360 - val_accuracy: 0.8125 - val_loss: 0.4505\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.3405 - val_accuracy: 0.8438 - val_loss: 0.4533\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.3221 - val_accuracy: 0.8438 - val_loss: 0.4424\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4081 - val_accuracy: 0.8438 - val_loss: 0.4545\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7796 - loss: 0.3844 - val_accuracy: 0.8438 - val_loss: 0.4652\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3156 - val_accuracy: 0.8125 - val_loss: 0.4623\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.2851 - val_accuracy: 0.8125 - val_loss: 0.4539\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8872 - loss: 0.2929 - val_accuracy: 0.7812 - val_loss: 0.4371\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8619 - loss: 0.2973 - val_accuracy: 0.8125 - val_loss: 0.4320\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.3257 - val_accuracy: 0.7812 - val_loss: 0.4290\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.2394 - val_accuracy: 0.7812 - val_loss: 0.4218\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3415 - val_accuracy: 0.7812 - val_loss: 0.4399\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3295 - val_accuracy: 0.7812 - val_loss: 0.4301\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2441 - val_accuracy: 0.7812 - val_loss: 0.4207\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3021 - val_accuracy: 0.7812 - val_loss: 0.4193\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.3105 - val_accuracy: 0.7812 - val_loss: 0.4237\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.9741 \n",
      "FNN Model Accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "model_fnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_fnn.fit(X_train_combined, y_train_combined, epochs=100, batch_size=5, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_fnn.evaluate(X_test_combined, y_test_combined)\n",
    "print(f\"FNN Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiHTR4mArbte"
   },
   "source": [
    "## FFNN with Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwLrgMnNrOxl",
    "outputId": "806cb4f8-251d-453a-b399-35005d1d77f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4370 - loss: 1.0319 - val_accuracy: 0.5938 - val_loss: 0.6867\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5217 - loss: 0.8853 - val_accuracy: 0.4375 - val_loss: 0.7129\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.7275 - val_accuracy: 0.4062 - val_loss: 0.7257\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4869 - loss: 0.9043 - val_accuracy: 0.3438 - val_loss: 0.7262\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5553 - loss: 0.8006 - val_accuracy: 0.3750 - val_loss: 0.7214\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.6462 - val_accuracy: 0.5312 - val_loss: 0.7093\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.7464 - val_accuracy: 0.4062 - val_loss: 0.7081\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6603 - loss: 0.6175 - val_accuracy: 0.4062 - val_loss: 0.7134\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6462 - loss: 0.5949 - val_accuracy: 0.4062 - val_loss: 0.7029\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6468 - loss: 0.6131 - val_accuracy: 0.3438 - val_loss: 0.7067\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 0.6767 - val_accuracy: 0.3438 - val_loss: 0.7064\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.6004 - val_accuracy: 0.4688 - val_loss: 0.6915\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5648 - loss: 0.6696 - val_accuracy: 0.5312 - val_loss: 0.6766\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5391 - val_accuracy: 0.5312 - val_loss: 0.6745\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5885 - loss: 0.6557 - val_accuracy: 0.5312 - val_loss: 0.6603\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5841 - loss: 0.6768 - val_accuracy: 0.5312 - val_loss: 0.6561\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6442 - loss: 0.5958 - val_accuracy: 0.5625 - val_loss: 0.6519\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 0.6108 - val_accuracy: 0.5938 - val_loss: 0.6435\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 0.6055 - val_accuracy: 0.6562 - val_loss: 0.6410\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5582 - loss: 0.6253 - val_accuracy: 0.5625 - val_loss: 0.6415\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.6005 - val_accuracy: 0.5625 - val_loss: 0.6440\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: 0.6137 - val_accuracy: 0.5625 - val_loss: 0.6397\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 0.5958 - val_accuracy: 0.5625 - val_loss: 0.6389\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6691 - loss: 0.6092 - val_accuracy: 0.5625 - val_loss: 0.6388\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.5859 - val_accuracy: 0.5625 - val_loss: 0.6400\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 0.6097 - val_accuracy: 0.6250 - val_loss: 0.6325\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6492 - loss: 0.5985 - val_accuracy: 0.6562 - val_loss: 0.6237\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6690 - loss: 0.5702 - val_accuracy: 0.6562 - val_loss: 0.6149\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6318 - loss: 0.5543 - val_accuracy: 0.6562 - val_loss: 0.6140\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.5841 - val_accuracy: 0.6562 - val_loss: 0.6141\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6574 - loss: 0.5527 - val_accuracy: 0.6250 - val_loss: 0.6085\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.5265 - val_accuracy: 0.6250 - val_loss: 0.6032\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7040 - loss: 0.5740 - val_accuracy: 0.6250 - val_loss: 0.6038\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5561 - val_accuracy: 0.6250 - val_loss: 0.6001\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7176 - loss: 0.5294 - val_accuracy: 0.6250 - val_loss: 0.5995\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6427 - loss: 0.5588 - val_accuracy: 0.6250 - val_loss: 0.6001\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.5656 - val_accuracy: 0.6250 - val_loss: 0.5985\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.4623 - val_accuracy: 0.6250 - val_loss: 0.5950\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7143 - loss: 0.5164 - val_accuracy: 0.6250 - val_loss: 0.5958\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.4953 - val_accuracy: 0.6562 - val_loss: 0.5890\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.4822 - val_accuracy: 0.6562 - val_loss: 0.5845\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.5268 - val_accuracy: 0.6875 - val_loss: 0.5807\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.4360 - val_accuracy: 0.6562 - val_loss: 0.5802\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7158 - loss: 0.4811 - val_accuracy: 0.6250 - val_loss: 0.5882\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.5335 - val_accuracy: 0.6562 - val_loss: 0.5894\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6799 - loss: 0.5012 - val_accuracy: 0.6562 - val_loss: 0.5831\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4729 - val_accuracy: 0.6875 - val_loss: 0.5749\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.4328 - val_accuracy: 0.6875 - val_loss: 0.5692\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4997 - val_accuracy: 0.6875 - val_loss: 0.5674\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4370 - val_accuracy: 0.6875 - val_loss: 0.5694\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.4448 - val_accuracy: 0.6875 - val_loss: 0.5639\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5078 - val_accuracy: 0.6875 - val_loss: 0.5648\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8248 - loss: 0.4302 - val_accuracy: 0.7188 - val_loss: 0.5616\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4464 - val_accuracy: 0.7188 - val_loss: 0.5677\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.4316 - val_accuracy: 0.7188 - val_loss: 0.5710\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.4695 - val_accuracy: 0.7188 - val_loss: 0.5743\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7363 - loss: 0.4592 - val_accuracy: 0.7188 - val_loss: 0.5781\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7317 - loss: 0.4622 - val_accuracy: 0.7188 - val_loss: 0.5757\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.4643 - val_accuracy: 0.7188 - val_loss: 0.5731\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.4046 - val_accuracy: 0.7500 - val_loss: 0.5639\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4293 - val_accuracy: 0.7500 - val_loss: 0.5615\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.4343 - val_accuracy: 0.7500 - val_loss: 0.5594\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.4218 - val_accuracy: 0.7500 - val_loss: 0.5537\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7232 - loss: 0.4753 - val_accuracy: 0.7500 - val_loss: 0.5596\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.4287 - val_accuracy: 0.7500 - val_loss: 0.5679\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.4967 - val_accuracy: 0.7500 - val_loss: 0.5641\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 0.4000 - val_accuracy: 0.7500 - val_loss: 0.5577\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.4755 - val_accuracy: 0.7500 - val_loss: 0.5549\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4029 - val_accuracy: 0.7500 - val_loss: 0.5558\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4037 - val_accuracy: 0.7500 - val_loss: 0.5472\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.3979 - val_accuracy: 0.7500 - val_loss: 0.5381\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3198 - val_accuracy: 0.7500 - val_loss: 0.5353\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.3286 - val_accuracy: 0.7500 - val_loss: 0.5399\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.3502 - val_accuracy: 0.7500 - val_loss: 0.5298\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.3904 - val_accuracy: 0.7500 - val_loss: 0.5265\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3807 - val_accuracy: 0.7500 - val_loss: 0.5170\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.4752 - val_accuracy: 0.7500 - val_loss: 0.5315\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.3608 - val_accuracy: 0.7500 - val_loss: 0.5403\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.3264 - val_accuracy: 0.7500 - val_loss: 0.5346\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.4697 - val_accuracy: 0.7500 - val_loss: 0.5354\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.3077 - val_accuracy: 0.7500 - val_loss: 0.5288\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.3504 - val_accuracy: 0.7500 - val_loss: 0.5267\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2741 - val_accuracy: 0.7812 - val_loss: 0.5196\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2582 - val_accuracy: 0.7812 - val_loss: 0.5055\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3343 - val_accuracy: 0.7812 - val_loss: 0.5152\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.3316 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.2347 - val_accuracy: 0.7812 - val_loss: 0.5317\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 0.4153 - val_accuracy: 0.7812 - val_loss: 0.5267\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.3836 - val_accuracy: 0.7812 - val_loss: 0.5303\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.3436 - val_accuracy: 0.7812 - val_loss: 0.5410\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.2806 - val_accuracy: 0.7812 - val_loss: 0.5365\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.2673 - val_accuracy: 0.7812 - val_loss: 0.5313\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8836 - loss: 0.3131 - val_accuracy: 0.8125 - val_loss: 0.5352\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3286 - val_accuracy: 0.8125 - val_loss: 0.5301\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.2838 - val_accuracy: 0.7812 - val_loss: 0.5419\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.3204 - val_accuracy: 0.7812 - val_loss: 0.5575\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3211 - val_accuracy: 0.7812 - val_loss: 0.5610\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8494 - loss: 0.2943 - val_accuracy: 0.7812 - val_loss: 0.5706\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2834 - val_accuracy: 0.7812 - val_loss: 0.5737\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3159 - val_accuracy: 0.7812 - val_loss: 0.5713\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5685 - loss: 0.8685\n",
      "FNN Model Accuracy: 0.5714285969734192\n"
     ]
    }
   ],
   "source": [
    "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
    "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
    "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
    "# Add sarcasm predictions as a new feature\n",
    "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
    "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
    "\n",
    "model_fnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(features_with_sarcasm_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_fnn.fit(features_with_sarcasm_train, y_train_combined, epochs=100, batch_size=5, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_fnn.evaluate(features_with_sarcasm_test, y_test_combined)\n",
    "print(f\"FNN Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzEW1dpCzwvY"
   },
   "source": [
    "## SVM without Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqD91-ZpsarR",
    "outputId": "1a9c3c68-c29f-408c-f778-a2ad5cdbe608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine (SVM) Results:\n",
      "Accuracy: 0.51\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56        20\n",
      "           1       0.44      0.47      0.45        15\n",
      "\n",
      "    accuracy                           0.51        35\n",
      "   macro avg       0.51      0.51      0.51        35\n",
      "weighted avg       0.52      0.51      0.52        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict with SVM\n",
    "y_pred_svm = svm_model.predict(X_test_combined)\n",
    "# Calculate probabilities for SVM\n",
    "y_pred_svm_proba = svm_model.decision_function(X_test_combined)  # For SVM, use decision_function for Precision-Recall\n",
    "\n",
    "\n",
    "# Evaluate SVM Model\n",
    "print(\"\\nSupport Vector Machine (SVM) Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_svm):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nN0v3Gg9aHTW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5owhnnrrhXIO"
   },
   "source": [
    "## Create Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIU6wPNFaHij",
    "outputId": "a63e43a2-c4b9-4261-a2e4-475072bc5e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
       "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'PCA_MFCC_1',\n",
       "       'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4', 'PCA_MFCC_5', 'PCA_MFCC_6',\n",
       "       'PCA_MFCC_7', 'PCA_MFCC_8', 'sentence_level_similarity_emotion',\n",
       "       'sentence_level_similarity_word', 'exclamation', 'PCA_W2V_1',\n",
       "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
       "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
       "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
       "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
       "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
       "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
       "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
       "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
       "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
       "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50', 'PCA_W2V_51',\n",
       "       'PCA_W2V_52', 'PCA_W2V_53', 'PCA_W2V_54', 'PCA_W2V_55', 'PCA_W2V_56',\n",
       "       'PCA_W2V_57', 'PCA_W2V_58', 'PCA_W2V_59', 'PCA_W2V_60', 'energy',\n",
       "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
       "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
       "       'mfccs_12', 'mfccs_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen = pd.read_csv('../datasets/sentiment_final.csv')\n",
    "df_sar = pd.read_csv('../datasets/sarcasm_final.csv')\n",
    "df_comb = pd.concat([df_sar, df_sen], ignore_index=True)\n",
    "\n",
    "df_comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "byn1gxepaHik"
   },
   "outputs": [],
   "source": [
    "# Define all the feature columns (text + audio features)\n",
    "all_feature_columns = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of text features for the text-only model\n",
    "feature_columns_text = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of audio features for the text-only model\n",
    "feature_columns_audio = [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MMpIuZNZaHik"
   },
   "outputs": [],
   "source": [
    "# target prediction\n",
    "target_column = 'sarcasm_label'\n",
    "\n",
    "# Prepare the feature set and target column for both models\n",
    "X_all = df_comb[all_feature_columns]\n",
    "y = df_comb[target_column]\n",
    "\n",
    "# Function to scale, split, and apply SMOTE\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test\n",
    "\n",
    "# --- Text-Only Model ---\n",
    "X_text = df_comb[feature_columns_text]\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = preprocess_data(X_text, y)\n",
    "\n",
    "# --- Audio-Only Model --- this is for following hybrid model\n",
    "X_audio = df_comb[feature_columns_audio]\n",
    "X_train_audio, X_test_audio, y_train_audio, y_test_audio = preprocess_data(X_audio, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3HolBhH7kK4y"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Combined Model (Text + Audio Features) ---\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-BVTX0TpiuQ"
   },
   "source": [
    "## Sentiment Model with Deep Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1Q4nUR2z0sP",
    "outputId": "04a64d89-32ab-4df5-a46d-4077da3720ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5828 - loss: 0.6689 - val_accuracy: 0.7674 - val_loss: 0.5526\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.5065 - val_accuracy: 0.7674 - val_loss: 0.4734\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.4381 - val_accuracy: 0.8256 - val_loss: 0.4395\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3918 - val_accuracy: 0.8488 - val_loss: 0.4255\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.3557 - val_accuracy: 0.8488 - val_loss: 0.4100\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.3198 - val_accuracy: 0.8372 - val_loss: 0.4020\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2950 - val_accuracy: 0.8372 - val_loss: 0.4042\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2771 - val_accuracy: 0.8488 - val_loss: 0.4077\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9028 - loss: 0.2538 - val_accuracy: 0.8372 - val_loss: 0.4070\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9259 - loss: 0.2304 - val_accuracy: 0.8372 - val_loss: 0.4128\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3964 \n",
      "Test Accuracy: 83.72%\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89        66\n",
      "           1       0.64      0.70      0.67        20\n",
      "\n",
      "    accuracy                           0.84        86\n",
      "   macro avg       0.77      0.79      0.78        86\n",
      "weighted avg       0.84      0.84      0.84        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_model(max_length, audio_feature_length, binary=True):\n",
    "    text_input = tf.keras.layers.Input(shape=(max_length,), name='text_input')\n",
    "    text_output = tf.keras.layers.Dense(128, activation='relu')(text_input)\n",
    "\n",
    "    audio_input = tf.keras.layers.Input(shape=(audio_feature_length,), name='audio_input')\n",
    "    audio_output = tf.keras.layers.Dense(128, activation='relu')(audio_input)\n",
    "\n",
    "    combined = tf.keras.layers.concatenate([text_output, audio_output])\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(combined)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    if binary:\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        output = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=[text_input, audio_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model for binary classification\n",
    "model = create_model(max_length=X_train_text.shape[1], audio_feature_length=X_train_audio.shape[1], binary=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    [X_train_text, X_train_audio], y_train_text,\n",
    "    validation_data=([X_test_text, X_test_audio], y_test_text),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate([X_test_text, X_test_audio], y_test_text)\n",
    "print(f\"Test Accuracy: {results[1]*100:.2f}%\")\n",
    "\n",
    "predicted_probs = model.predict([X_test_text, X_test_audio])\n",
    "predicted_labels = (predicted_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, predicted_labels):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCSdzchtpsMN"
   },
   "source": [
    "## Sentiment Model with Deep Neural Network + Sarcasm as feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PsO0LSrzpqsk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmSO_61DYR5I",
    "outputId": "597171a2-020a-49e6-90d6-d8dd6c4fc3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5525 - loss: 0.7120\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7682 - loss: 0.5112 \n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.4267\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3735 \n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3214 \n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.3025 \n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2663 \n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2214\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.2073\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2043 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.2927  \n",
      "Test Accuracy: 88.37%\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        66\n",
      "           1       0.69      0.90      0.78        20\n",
      "\n",
      "    accuracy                           0.88        86\n",
      "   macro avg       0.83      0.89      0.85        86\n",
      "weighted avg       0.90      0.88      0.89        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
    "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
    "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
    "# Add sarcasm predictions as a new feature\n",
    "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
    "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_model(feature_length, binary=True):\n",
    "    # Input layer to accommodate text, audio, and sarcasm features\n",
    "    inputs = tf.keras.layers.Input(shape=(feature_length,), name='combined_input')\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Output layer configuration based on binary or categorical\n",
    "    if binary:\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Determine the feature length based on your new combined datasets\n",
    "feature_length = features_with_sarcasm_train.shape[1]\n",
    "\n",
    "# Create the model\n",
    "model = create_model(feature_length, binary=True)\n",
    "\n",
    "# Fit the model using the enhanced datasets\n",
    "history = model.fit(\n",
    "    features_with_sarcasm_train, y_train_text,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(features_with_sarcasm_test, y_test_text)\n",
    "print(f\"Test Accuracy: {results[1]*100:.2f}%\")\n",
    "\n",
    "predicted_probs = model.predict(features_with_sarcasm_test)\n",
    "predicted_labels = (predicted_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, predicted_labels):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, predicted_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QketZmjmpxic"
   },
   "source": [
    "## Sentiment Model with Deep Neural Network + Sarcasm Sentiment Set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGzKagSWpJoC",
    "outputId": "4d9d4d92-0b46-4729-ad69-303e842e4f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 0.73\n",
      "Adjusted Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.85        66\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.73        86\n",
      "   macro avg       0.38      0.48      0.42        86\n",
      "weighted avg       0.58      0.73      0.65        86\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      " [[63  3]\n",
      " [20  0]]\n"
     ]
    }
   ],
   "source": [
    "final_predicted_labels = np.where(sarcasm_predictions_test == 1, 0, predicted_labels)\n",
    "\n",
    "# Calculate accuracy and other metrics after adjusting for sarcasm\n",
    "print(f\"Adjusted Accuracy: {accuracy_score(y_test_text, final_predicted_labels):.2f}\")\n",
    "print(\"Adjusted Classification Report:\\n\", classification_report(y_test_text, final_predicted_labels))\n",
    "print(\"Adjusted Confusion Matrix:\\n\", confusion_matrix(y_test_text, final_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIl-c-YjrGng"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
