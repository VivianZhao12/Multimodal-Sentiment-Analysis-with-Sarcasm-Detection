{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmZ7TT_ZX1QF",
        "outputId": "39e4637d-de67-4d76-963c-fbe8abce5d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multimodal-Sentiment-Analysis-with-Sarcasm-Detection'...\n",
            "remote: Enumerating objects: 1404, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 1404 (delta 37), reused 53 (delta 18), pack-reused 1315 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1404/1404), 324.45 MiB | 23.10 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Updating files: 100% (884/884), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/VivianZhao12/Multimodal-Sentiment-Analysis-with-Sarcasm-Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import imblearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "#import scikitplot as skplt\n",
        "import statsmodels.api as sm\n",
        "import random\n",
        "\n",
        "from sklearn.svm import SVC  # Importing Support Vector Classifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE  # For oversampling\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import tensorflow as tf\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization, Layer, Softmax, Activation, Conv1D, MaxPooling1D, Flatten, LSTM, InputLayer\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K"
      ],
      "metadata": {
        "id": "YklIVwNqY2TS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sar = pd.read_csv('sarcasm_final.csv')\n",
        "df_sar.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou6odKSvaI7S",
        "outputId": "4d50f259-96c8-4774-e0ac-2f21b0e0b3a6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
              "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'PCA_MFCC_1',\n",
              "       'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4', 'PCA_MFCC_5', 'PCA_MFCC_6',\n",
              "       'PCA_MFCC_7', 'PCA_MFCC_8', 'sentence_level_similarity_emotion',\n",
              "       'sentence_level_similarity_word', 'exclamation', 'PCA_W2V_1',\n",
              "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
              "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
              "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
              "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
              "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
              "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
              "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
              "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
              "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
              "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50', 'PCA_W2V_51',\n",
              "       'PCA_W2V_52', 'PCA_W2V_53', 'PCA_W2V_54', 'PCA_W2V_55', 'PCA_W2V_56',\n",
              "       'PCA_W2V_57', 'PCA_W2V_58', 'PCA_W2V_59', 'PCA_W2V_60', 'energy',\n",
              "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
              "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
              "       'mfccs_12', 'mfccs_13'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define all the feature columns (text + audio features)\n",
        "all_feature_columns = [\n",
        "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
        "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
        "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
        "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
        "\n",
        "# Select a subset of text features for the text-only model\n",
        "feature_columns_text = [\n",
        "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
        "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
        "\n",
        "# Select a subset of audio features for the text-only model\n",
        "feature_columns_audio = [\n",
        "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
        "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
      ],
      "metadata": {
        "id": "s-Y7O8-qaK-X"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target prediction\n",
        "target_column = 'sarcasm_label'\n",
        "\n",
        "# Prepare the feature set and target column for both models\n",
        "X_all = df_sar[all_feature_columns]\n",
        "y = df_sar[target_column]\n",
        "\n",
        "# Function to scale, split, and apply SMOTE\n",
        "def preprocess_data(X, y):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "    return X_train_resampled, X_test, y_train_resampled, y_test\n",
        "\n",
        "# --- Text-Only Model ---\n",
        "X_text = df_sar[feature_columns_text]\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = preprocess_data(X_text, y)\n",
        "\n",
        "# --- Audio-Only Model --- this is for following hybrid model\n",
        "X_audio = df_sar[feature_columns_audio]\n",
        "X_train_audio, X_test_audio, y_train_audio, y_test_audio = preprocess_data(X_audio, y)"
      ],
      "metadata": {
        "id": "nSSkvQaIaN2a"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with text features\n",
        "logistic_model_text = LogisticRegression(max_iter=500, random_state=42)\n",
        "logistic_model_text.fit(X_train_text, y_train_text)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_text = logistic_model_text.predict(X_test_text)\n",
        "\n",
        "# --- Combined Model (Text + Audio Features) ---\n",
        "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)\n",
        "\n",
        "# Logistic Regression with both text and audio features\n",
        "logistic_model_combined = LogisticRegression(max_iter=500, random_state=42)\n",
        "logistic_model_combined.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_combined = logistic_model_combined.predict(X_test_combined)\n",
        "y_pred_logistic_proba = logistic_model_combined.decision_function(X_test_combined)"
      ],
      "metadata": {
        "id": "tBrkqKBTaQTW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Results (Text-Only Model)\n",
        "accuracy_text = accuracy_score(y_test_text, y_pred_text)\n",
        "cm_text = confusion_matrix(y_test_text, y_pred_text)\n",
        "cr_text = classification_report(y_test_text, y_pred_text, output_dict=True)\n",
        "\n",
        "# Evaluation Results (Combined Model)\n",
        "accuracy_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
        "cm_combined = confusion_matrix(y_test_combined, y_pred_combined)\n",
        "cr_combined = classification_report(y_test_combined, y_pred_combined, output_dict=True)"
      ],
      "metadata": {
        "id": "a9jo2MlZdIlX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_text.columns contains the correct feature names\n",
        "feature_names = ['Intercept'] + list(X_all.columns)\n",
        "\n",
        "# Add an intercept to the combined dataset\n",
        "X_train_combined_with_intercept = sm.add_constant(X_train_combined)\n",
        "\n",
        "# Fit the logistic regression model using statsmodels\n",
        "logit_model = sm.Logit(y_train_combined, X_train_combined_with_intercept)\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Convert the result summary to a DataFrame and replace the index with feature names\n",
        "summary_table = result.summary2().tables[1]  # Get the coefficient table\n",
        "summary_table.index = feature_names  # Replace generic 'x1', 'x2', ... with actual names\n",
        "\n",
        "sorted_summary = summary_table.sort_values(by='P>|z|')\n",
        "\n",
        "# Identify significant features based on p-value\n",
        "significant_features = summary_table[summary_table['P>|z|'] < 0.01]\n",
        "\n",
        "# Sort significant features by the absolute value of their coefficients\n",
        "significant_features_sorted = significant_features.reindex(\n",
        "    significant_features['Coef.'].abs().sort_values(ascending=False).index\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31wMFz4rdOiD",
        "outputId": "97d86ca7-6754-4139-ab90-195786906f68"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.318500\n",
            "         Iterations 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM) Model\n",
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Predict with SVM\n",
        "y_pred_svm = svm_model.predict(X_test_combined)\n",
        "# Calculate probabilities for SVM\n",
        "y_pred_svm_proba = svm_model.decision_function(X_test_combined)  # For SVM, use decision_function for Precision-Recall\n",
        "\n",
        "\n",
        "# Evaluate SVM Model\n",
        "print(\"\\nSupport Vector Machine (SVM) Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_svm):.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "604qfkNTdT6c",
        "outputId": "72b78e66-7dc6-45bd-84ff-8688ad7516f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Support Vector Machine (SVM) Results:\n",
            "Accuracy: 0.79\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.85        38\n",
            "           1       0.59      0.71      0.65        14\n",
            "\n",
            "    accuracy                           0.79        52\n",
            "   macro avg       0.74      0.77      0.75        52\n",
            "weighted avg       0.81      0.79      0.79        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes Model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_combined, y_train_combined)\n",
        "y_pred_nb_proba = nb_model.predict(X_test_combined)\n",
        "\n",
        "# Evaluate Naive Bayes Model\n",
        "print(\"\\nNaive Bayes Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_nb_proba):.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_nb_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-U3spqQdYGE",
        "outputId": "1035c7e9-a2ae-4fc7-af41-52c59fb24b5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Naive Bayes Results:\n",
            "Accuracy: 0.77\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.76      0.83        38\n",
            "           1       0.55      0.79      0.65        14\n",
            "\n",
            "    accuracy                           0.77        52\n",
            "   macro avg       0.73      0.77      0.74        52\n",
            "weighted avg       0.81      0.77      0.78        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model\n",
        "clf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred_clf = clf_model.predict(X_test_combined)\n",
        "\n",
        "# Calculating the accuracy\n",
        "accuracy_clf = accuracy_score(y_test_combined, y_pred_clf)\n",
        "\n",
        "# Generating a classification report\n",
        "class_report = classification_report(y_test_combined, y_pred_clf)\n",
        "\n",
        "# Printing out the results\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "print(f\"Accuracy: {accuracy_clf:.2f}\")\n",
        "print(\"Classification Report:\\n\", class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7dbX8OudbnD",
        "outputId": "b95e1192-fc7c-44d6-c583-7ba9e87ab308"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.81\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87        38\n",
            "           1       0.67      0.57      0.62        14\n",
            "\n",
            "    accuracy                           0.81        52\n",
            "   macro avg       0.76      0.73      0.74        52\n",
            "weighted avg       0.80      0.81      0.80        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracies for each model\n",
        "accuracy_logistic = logistic_model_combined.score(X_test_combined, y_test_combined)\n",
        "accuracy_svm = svm_model.score(X_test_combined, y_test_combined)\n",
        "accuracy_nb = nb_model.score(X_test_combined, y_test_combined)\n",
        "\n",
        "# Print accuracy values\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.2f}\")\n",
        "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
        "print(f\"Random Forest Accuracy: {accuracy_clf:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dEcG1bldhrT",
        "outputId": "b77c35bb-037e-4776-91f5-1df5eaeb3a02"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.77\n",
            "SVM Accuracy: 0.79\n",
            "Naive Bayes Accuracy: 0.77\n",
            "Random Forest Accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Precision-Recall\n",
        "precision_logistic, recall_logistic, _ = precision_recall_curve(y_test_combined, y_pred_logistic_proba)\n",
        "pr_auc_logistic = auc(recall_logistic, precision_logistic)\n",
        "\n",
        "# SVM Precision-Recall\n",
        "precision_svm, recall_svm, _ = precision_recall_curve(y_test_combined, y_pred_svm_proba)\n",
        "pr_auc_svm = auc(recall_svm, precision_svm)\n",
        "\n",
        "# Naive Bayes Precision-Recall\n",
        "precision_nb, recall_nb, _ = precision_recall_curve(y_test_combined, y_pred_nb_proba)\n",
        "pr_auc_nb = auc(recall_nb, precision_nb)\n",
        "\n",
        "# Assuming clf_rf is your trained Random Forest classifier\n",
        "y_pred_rf_proba = clf_model.predict_proba(X_test_combined)[:, 1]\n",
        "precision_rf, recall_rf, _ = precision_recall_curve(y_test_combined, y_pred_rf_proba)\n",
        "pr_auc_rf = auc(recall_rf, precision_rf)\n",
        "\n",
        "# Compute ROC curves and AUC scores\n",
        "fpr_logistic, tpr_logistic, _ = roc_curve(y_test_combined, y_pred_logistic_proba)\n",
        "fpr_nb, tpr_nb, _ = roc_curve(y_test_combined, y_pred_nb_proba)\n",
        "fpr_svm, tpr_svm, _ = roc_curve(y_test_combined, y_pred_svm_proba)\n",
        "\n",
        "auc_logistic = roc_auc_score(y_test_combined, y_pred_logistic_proba)\n",
        "auc_svm = roc_auc_score(y_test_combined, y_pred_svm_proba)\n",
        "auc_nb = roc_auc_score(y_test_combined, y_pred_nb_proba)\n",
        "\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test_combined, y_pred_rf_proba)\n",
        "auc_rf = roc_auc_score(y_test_combined, y_pred_rf_proba)"
      ],
      "metadata": {
        "id": "BqTuKbQedjKz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Ensuring the same random seed is used every time before any layer weights are initialized\n",
        "# Build a full connect neural network\n",
        "model_FCNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_FCNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model_FCNN.fit(X_train_combined, y_train_combined, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "fcnn_loss, fcnn_accuracy = model_FCNN.evaluate(X_test_combined, y_test_combined)\n",
        "print(f'FCNN Accuracy: {fcnn_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAofh4z4dn77",
        "outputId": "384e60f8-f65c-4cb6-8e33-fe256503754c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5851 - loss: 0.6845 - val_accuracy: 0.0167 - val_loss: 0.8102\n",
            "Epoch 2/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5604 - loss: 0.6930 - val_accuracy: 0.0500 - val_loss: 0.8005\n",
            "Epoch 3/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6461 - loss: 0.5887 - val_accuracy: 0.1333 - val_loss: 0.7831\n",
            "Epoch 4/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6502 - loss: 0.6126 - val_accuracy: 0.4167 - val_loss: 0.7517\n",
            "Epoch 5/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5983 - loss: 0.6396 - val_accuracy: 0.5833 - val_loss: 0.7159\n",
            "Epoch 6/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6498 - loss: 0.5753 - val_accuracy: 0.7667 - val_loss: 0.6757\n",
            "Epoch 7/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7206 - loss: 0.5669 - val_accuracy: 0.8000 - val_loss: 0.6513\n",
            "Epoch 8/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7191 - loss: 0.5607 - val_accuracy: 0.8167 - val_loss: 0.6200\n",
            "Epoch 9/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7102 - loss: 0.5372 - val_accuracy: 0.8500 - val_loss: 0.5917\n",
            "Epoch 10/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7715 - loss: 0.5047 - val_accuracy: 0.8500 - val_loss: 0.5600\n",
            "Epoch 11/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.5110 - val_accuracy: 0.8500 - val_loss: 0.5354\n",
            "Epoch 12/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7376 - loss: 0.4777 - val_accuracy: 0.8667 - val_loss: 0.5069\n",
            "Epoch 13/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7657 - loss: 0.4735 - val_accuracy: 0.8833 - val_loss: 0.4801\n",
            "Epoch 14/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7687 - loss: 0.5167 - val_accuracy: 0.8833 - val_loss: 0.4604\n",
            "Epoch 15/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7903 - loss: 0.4858 - val_accuracy: 0.8833 - val_loss: 0.4421\n",
            "Epoch 16/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8078 - loss: 0.4227 - val_accuracy: 0.8833 - val_loss: 0.4248\n",
            "Epoch 17/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8150 - loss: 0.4384 - val_accuracy: 0.8833 - val_loss: 0.4175\n",
            "Epoch 18/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7626 - loss: 0.4738 - val_accuracy: 0.9000 - val_loss: 0.4064\n",
            "Epoch 19/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8096 - loss: 0.4510 - val_accuracy: 0.9000 - val_loss: 0.3825\n",
            "Epoch 20/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 0.4046 - val_accuracy: 0.9333 - val_loss: 0.3604\n",
            "Epoch 21/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8225 - loss: 0.4322 - val_accuracy: 0.9333 - val_loss: 0.3441\n",
            "Epoch 22/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8215 - loss: 0.3886 - val_accuracy: 0.9333 - val_loss: 0.3256\n",
            "Epoch 23/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8182 - loss: 0.3927 - val_accuracy: 0.9333 - val_loss: 0.3144\n",
            "Epoch 24/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8607 - loss: 0.3656 - val_accuracy: 0.9333 - val_loss: 0.3027\n",
            "Epoch 25/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7754 - loss: 0.4299 - val_accuracy: 0.9333 - val_loss: 0.3001\n",
            "Epoch 26/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7902 - loss: 0.4207 - val_accuracy: 0.9333 - val_loss: 0.2992\n",
            "Epoch 27/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8312 - loss: 0.3750 - val_accuracy: 0.9333 - val_loss: 0.3011\n",
            "Epoch 28/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8392 - loss: 0.3162 - val_accuracy: 0.9333 - val_loss: 0.3002\n",
            "Epoch 29/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.3873 - val_accuracy: 0.9333 - val_loss: 0.2926\n",
            "Epoch 30/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8206 - loss: 0.3834 - val_accuracy: 0.9333 - val_loss: 0.2848\n",
            "Epoch 31/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7747 - loss: 0.4080 - val_accuracy: 0.9333 - val_loss: 0.2841\n",
            "Epoch 32/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8343 - loss: 0.3424 - val_accuracy: 0.9333 - val_loss: 0.2753\n",
            "Epoch 33/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8238 - loss: 0.3685 - val_accuracy: 0.9333 - val_loss: 0.2652\n",
            "Epoch 34/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8569 - loss: 0.3580 - val_accuracy: 0.9333 - val_loss: 0.2584\n",
            "Epoch 35/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8202 - loss: 0.3685 - val_accuracy: 0.9333 - val_loss: 0.2507\n",
            "Epoch 36/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8705 - loss: 0.3306 - val_accuracy: 0.9333 - val_loss: 0.2434\n",
            "Epoch 37/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8489 - loss: 0.3149 - val_accuracy: 0.9167 - val_loss: 0.2368\n",
            "Epoch 38/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8476 - loss: 0.2965 - val_accuracy: 0.9333 - val_loss: 0.2276\n",
            "Epoch 39/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8771 - loss: 0.3310 - val_accuracy: 0.9333 - val_loss: 0.2220\n",
            "Epoch 40/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8490 - loss: 0.3381 - val_accuracy: 0.9333 - val_loss: 0.2184\n",
            "Epoch 41/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8799 - loss: 0.3086 - val_accuracy: 0.9333 - val_loss: 0.2125\n",
            "Epoch 42/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8694 - loss: 0.3015 - val_accuracy: 0.9333 - val_loss: 0.2151\n",
            "Epoch 43/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8979 - loss: 0.2996 - val_accuracy: 0.9333 - val_loss: 0.2108\n",
            "Epoch 44/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8209 - loss: 0.3374 - val_accuracy: 0.9333 - val_loss: 0.2080\n",
            "Epoch 45/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8891 - loss: 0.3053 - val_accuracy: 0.9333 - val_loss: 0.2022\n",
            "Epoch 46/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8800 - loss: 0.2407 - val_accuracy: 0.9333 - val_loss: 0.1908\n",
            "Epoch 47/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8560 - loss: 0.3361 - val_accuracy: 0.9333 - val_loss: 0.1825\n",
            "Epoch 48/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.3031 - val_accuracy: 0.9333 - val_loss: 0.1861\n",
            "Epoch 49/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8484 - loss: 0.3399 - val_accuracy: 0.9333 - val_loss: 0.1916\n",
            "Epoch 50/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8860 - loss: 0.2627 - val_accuracy: 0.9333 - val_loss: 0.1917\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8221 - loss: 0.4752 \n",
            "FCNN Accuracy: 0.8269230723381042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_FCNN.save(\"model_FCNN.keras\")"
      ],
      "metadata": {
        "id": "f_an5vJ9faB8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Build a more robust fully connected neural network\n",
        "model_ehFCNN = Sequential([\n",
        "    InputLayer(input_shape=(X_train_combined.shape[1],)),\n",
        "\n",
        "    Dense(64, kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Optimizer with a learning rate schedule\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_ehFCNN.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and saving the best model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model with validation split and callbacks\n",
        "history = model_ehFCNN.fit(\n",
        "    X_train_combined,\n",
        "    y_train_combined,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "fcnn_loss, fcnn_accuracy = model_ehFCNN.evaluate(X_test_combined, y_test_combined)\n",
        "print(f'Enhanced FCNN Model Accuracy: {fcnn_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14OYeL6od-in",
        "outputId": "7c2760c7-df6d-4862-c4e3-29c88e8d75cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - accuracy: 0.5478 - loss: 1.6533 - val_accuracy: 0.0500 - val_loss: 1.6955\n",
            "Epoch 2/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5885 - loss: 1.5467 - val_accuracy: 0.3500 - val_loss: 1.6234\n",
            "Epoch 3/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7010 - loss: 1.4232 - val_accuracy: 0.6667 - val_loss: 1.5498\n",
            "Epoch 4/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7476 - loss: 1.4069 - val_accuracy: 0.8000 - val_loss: 1.4839\n",
            "Epoch 5/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7208 - loss: 1.3477 - val_accuracy: 0.8667 - val_loss: 1.4236\n",
            "Epoch 6/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7443 - loss: 1.2948 - val_accuracy: 0.9000 - val_loss: 1.3587\n",
            "Epoch 7/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7943 - loss: 1.2591 - val_accuracy: 0.9167 - val_loss: 1.3038\n",
            "Epoch 8/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8329 - loss: 1.1972 - val_accuracy: 0.9333 - val_loss: 1.2512\n",
            "Epoch 9/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8320 - loss: 1.1769 - val_accuracy: 0.9333 - val_loss: 1.1992\n",
            "Epoch 10/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8062 - loss: 1.1386 - val_accuracy: 0.9333 - val_loss: 1.1480\n",
            "Epoch 11/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8285 - loss: 1.0865 - val_accuracy: 0.9333 - val_loss: 1.1056\n",
            "Epoch 12/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8219 - loss: 1.0730 - val_accuracy: 0.9333 - val_loss: 1.0681\n",
            "Epoch 13/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.8561 - loss: 1.0007 - val_accuracy: 0.9333 - val_loss: 1.0314\n",
            "Epoch 14/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8433 - loss: 1.0054 - val_accuracy: 0.9333 - val_loss: 0.9948\n",
            "Epoch 15/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8317 - loss: 0.9978 - val_accuracy: 0.9333 - val_loss: 0.9619\n",
            "Epoch 16/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8383 - loss: 0.9309 - val_accuracy: 0.9333 - val_loss: 0.9267\n",
            "Epoch 17/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8230 - loss: 0.9465 - val_accuracy: 0.9333 - val_loss: 0.8993\n",
            "Epoch 18/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8326 - loss: 0.9194 - val_accuracy: 0.9333 - val_loss: 0.8750\n",
            "Epoch 19/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8573 - loss: 0.8756 - val_accuracy: 0.9333 - val_loss: 0.8472\n",
            "Epoch 20/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8865 - loss: 0.8100 - val_accuracy: 0.9333 - val_loss: 0.8171\n",
            "Epoch 21/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8937 - loss: 0.8145 - val_accuracy: 0.9333 - val_loss: 0.7879\n",
            "Epoch 22/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8640 - loss: 0.7737 - val_accuracy: 0.9333 - val_loss: 0.7607\n",
            "Epoch 23/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8797 - loss: 0.7848 - val_accuracy: 0.9333 - val_loss: 0.7376\n",
            "Epoch 24/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8939 - loss: 0.7261 - val_accuracy: 0.9333 - val_loss: 0.7165\n",
            "Epoch 25/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9178 - loss: 0.7095 - val_accuracy: 0.9333 - val_loss: 0.6984\n",
            "Epoch 26/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8543 - loss: 0.7420 - val_accuracy: 0.9333 - val_loss: 0.6765\n",
            "Epoch 27/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.6619 - val_accuracy: 0.9333 - val_loss: 0.6606\n",
            "Epoch 28/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9176 - loss: 0.6471 - val_accuracy: 0.9333 - val_loss: 0.6475\n",
            "Epoch 29/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8711 - loss: 0.6617 - val_accuracy: 0.9333 - val_loss: 0.6324\n",
            "Epoch 30/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9222 - loss: 0.6183 - val_accuracy: 0.9333 - val_loss: 0.6189\n",
            "Epoch 31/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9071 - loss: 0.6233 - val_accuracy: 0.9333 - val_loss: 0.6080\n",
            "Epoch 32/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9193 - loss: 0.5876 - val_accuracy: 0.9333 - val_loss: 0.5939\n",
            "Epoch 33/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9359 - loss: 0.5720 - val_accuracy: 0.9333 - val_loss: 0.5789\n",
            "Epoch 34/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9157 - loss: 0.5768 - val_accuracy: 0.9500 - val_loss: 0.5603\n",
            "Epoch 35/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9154 - loss: 0.5547 - val_accuracy: 0.9500 - val_loss: 0.5418\n",
            "Epoch 36/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9194 - loss: 0.5104 - val_accuracy: 0.9500 - val_loss: 0.5254\n",
            "Epoch 37/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9362 - loss: 0.5216 - val_accuracy: 0.9500 - val_loss: 0.5100\n",
            "Epoch 38/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.4744 - val_accuracy: 0.9500 - val_loss: 0.4923\n",
            "Epoch 39/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9202 - loss: 0.5006 - val_accuracy: 0.9500 - val_loss: 0.4801\n",
            "Epoch 40/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9260 - loss: 0.5030 - val_accuracy: 0.9500 - val_loss: 0.4716\n",
            "Epoch 41/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9159 - loss: 0.5056 - val_accuracy: 0.9500 - val_loss: 0.4681\n",
            "Epoch 42/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9496 - loss: 0.4312 - val_accuracy: 0.9500 - val_loss: 0.4625\n",
            "Epoch 43/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9448 - loss: 0.4642 - val_accuracy: 0.9500 - val_loss: 0.4497\n",
            "Epoch 44/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9522 - loss: 0.4543 - val_accuracy: 0.9500 - val_loss: 0.4379\n",
            "Epoch 45/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.4153 - val_accuracy: 0.9500 - val_loss: 0.4278\n",
            "Epoch 46/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9712 - loss: 0.3871 - val_accuracy: 0.9500 - val_loss: 0.4109\n",
            "Epoch 47/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9496 - loss: 0.4154 - val_accuracy: 0.9500 - val_loss: 0.3952\n",
            "Epoch 48/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9511 - loss: 0.3906 - val_accuracy: 0.9500 - val_loss: 0.3895\n",
            "Epoch 49/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9429 - loss: 0.3884 - val_accuracy: 0.9500 - val_loss: 0.3920\n",
            "Epoch 50/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9577 - loss: 0.3707 - val_accuracy: 0.9500 - val_loss: 0.3820\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7628 - loss: 0.7504 \n",
            "Enhanced FCNN Model Accuracy: 0.7692307829856873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "def build_hybrid_model(num_text_features, num_audio_features, regularization_rate=0.01):\n",
        "    # Text input branch\n",
        "    text_input = Input(shape=(num_text_features,), name='text_input')\n",
        "    text_hidden = Dense(128, activation='relu', kernel_regularizer=l2(regularization_rate))(text_input)\n",
        "    text_hidden = BatchNormalization()(text_hidden)\n",
        "    text_hidden = Dropout(0.3)(text_hidden)\n",
        "\n",
        "    # Audio input branch\n",
        "    audio_input = Input(shape=(num_audio_features,), name='audio_input')\n",
        "    audio_hidden = Dense(128, activation='relu', kernel_regularizer=l2(regularization_rate))(audio_input)\n",
        "    audio_hidden = BatchNormalization()(audio_hidden)\n",
        "    audio_hidden = Dropout(0.3)(audio_hidden)\n",
        "\n",
        "    # Concatenate both branches\n",
        "    concatenated = Concatenate()([text_hidden, audio_hidden])\n",
        "    concatenated = Dense(64, activation='relu', kernel_regularizer=l2(regularization_rate))(concatenated)\n",
        "    concatenated = Dropout(0.3)(concatenated)\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(1, activation='sigmoid')(concatenated)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = Model(inputs=[text_input, audio_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "model_ehhb = build_hybrid_model(num_text_features=11, num_audio_features=11)\n",
        "\n",
        "# Callbacks for early stopping and model checkpointing\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Assume X_train_text, X_train_audio, y_train_combined are prepared\n",
        "# and similarly for X_test_text, X_test_audio, y_test_combined\n",
        "history = model_ehhb.fit(\n",
        "    [X_train_text, X_train_audio],\n",
        "    y_train_combined,\n",
        "    validation_data=([X_test_text, X_test_audio], y_test_combined),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "ehhb_accuracy = model_ehhb.evaluate([X_test_text, X_test_audio], y_test_combined)[1]\n",
        "print(\"Hybrid Model Accuracy:\", ehhb_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxM5v5GkYCZT",
        "outputId": "fcb9d62c-f2bc-40cf-a504-b8ef1504f029"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6228 - loss: 2.2666 - val_accuracy: 0.7308 - val_loss: 2.0007\n",
            "Epoch 2/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8281 - loss: 1.7813 - val_accuracy: 0.7500 - val_loss: 1.8690\n",
            "Epoch 3/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8478 - loss: 1.6895 - val_accuracy: 0.7692 - val_loss: 1.7872\n",
            "Epoch 4/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8988 - loss: 1.5809 - val_accuracy: 0.7885 - val_loss: 1.7248\n",
            "Epoch 5/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8794 - loss: 1.4910 - val_accuracy: 0.7692 - val_loss: 1.6694\n",
            "Epoch 6/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8331 - loss: 1.5130 - val_accuracy: 0.7308 - val_loss: 1.6226\n",
            "Epoch 7/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8981 - loss: 1.3866 - val_accuracy: 0.7500 - val_loss: 1.5783\n",
            "Epoch 8/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9277 - loss: 1.3058 - val_accuracy: 0.7308 - val_loss: 1.5295\n",
            "Epoch 9/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9510 - loss: 1.2018 - val_accuracy: 0.7692 - val_loss: 1.4858\n",
            "Epoch 10/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8961 - loss: 1.2225 - val_accuracy: 0.7500 - val_loss: 1.4326\n",
            "Epoch 11/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9065 - loss: 1.1635 - val_accuracy: 0.7308 - val_loss: 1.3835\n",
            "Epoch 12/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9607 - loss: 1.0745 - val_accuracy: 0.7500 - val_loss: 1.3356\n",
            "Epoch 13/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9291 - loss: 1.0542 - val_accuracy: 0.7500 - val_loss: 1.3015\n",
            "Epoch 14/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 1.0231 - val_accuracy: 0.7500 - val_loss: 1.2717\n",
            "Epoch 15/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9530 - loss: 0.9553 - val_accuracy: 0.7500 - val_loss: 1.2418\n",
            "Epoch 16/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9500 - loss: 0.9307 - val_accuracy: 0.7308 - val_loss: 1.2128\n",
            "Epoch 17/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.8851 - val_accuracy: 0.7692 - val_loss: 1.1812\n",
            "Epoch 18/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.8644 - val_accuracy: 0.7692 - val_loss: 1.1498\n",
            "Epoch 19/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.8361 - val_accuracy: 0.7500 - val_loss: 1.1163\n",
            "Epoch 20/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9526 - loss: 0.8184 - val_accuracy: 0.7692 - val_loss: 1.0960\n",
            "Epoch 21/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9565 - loss: 0.7982 - val_accuracy: 0.7500 - val_loss: 1.0768\n",
            "Epoch 22/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9683 - loss: 0.7399 - val_accuracy: 0.7500 - val_loss: 1.0609\n",
            "Epoch 23/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9620 - loss: 0.7156 - val_accuracy: 0.7500 - val_loss: 1.0425\n",
            "Epoch 24/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.6838 - val_accuracy: 0.7500 - val_loss: 1.0216\n",
            "Epoch 25/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.6677 - val_accuracy: 0.7500 - val_loss: 1.0021\n",
            "Epoch 26/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9712 - loss: 0.6534 - val_accuracy: 0.7500 - val_loss: 0.9757\n",
            "Epoch 27/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9501 - loss: 0.6651 - val_accuracy: 0.7500 - val_loss: 0.9605\n",
            "Epoch 28/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.5964 - val_accuracy: 0.7500 - val_loss: 0.9425\n",
            "Epoch 29/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9667 - loss: 0.5822 - val_accuracy: 0.7500 - val_loss: 0.9273\n",
            "Epoch 30/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.5641 - val_accuracy: 0.7500 - val_loss: 0.9182\n",
            "Epoch 31/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9801 - loss: 0.5380 - val_accuracy: 0.7692 - val_loss: 0.9101\n",
            "Epoch 32/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.5012 - val_accuracy: 0.7692 - val_loss: 0.8977\n",
            "Epoch 33/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9750 - loss: 0.5058 - val_accuracy: 0.7500 - val_loss: 0.8841\n",
            "Epoch 34/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9970 - loss: 0.4682 - val_accuracy: 0.7500 - val_loss: 0.8777\n",
            "Epoch 35/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9935 - loss: 0.4613 - val_accuracy: 0.7692 - val_loss: 0.8644\n",
            "Epoch 36/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9742 - loss: 0.4681 - val_accuracy: 0.7692 - val_loss: 0.8570\n",
            "Epoch 37/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 0.4395 - val_accuracy: 0.7692 - val_loss: 0.8393\n",
            "Epoch 38/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9927 - loss: 0.4241 - val_accuracy: 0.7692 - val_loss: 0.8249\n",
            "Epoch 39/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9766 - loss: 0.4139 - val_accuracy: 0.7692 - val_loss: 0.8248\n",
            "Epoch 40/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9808 - loss: 0.4065 - val_accuracy: 0.7692 - val_loss: 0.8292\n",
            "Epoch 41/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.3779 - val_accuracy: 0.7692 - val_loss: 0.8323\n",
            "Epoch 42/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.3668 - val_accuracy: 0.7500 - val_loss: 0.8337\n",
            "Epoch 43/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.3568 - val_accuracy: 0.7500 - val_loss: 0.8323\n",
            "Epoch 44/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.3317 - val_accuracy: 0.7500 - val_loss: 0.8306\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7524 - loss: 0.7999 \n",
            "Hybrid Model Accuracy: 0.7692307829856873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SlwIkV7fvn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Model"
      ],
      "metadata": {
        "id": "nViLzrlEgCNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sen = pd.read_csv('sentiment_final.csv')\n",
        "df_sen.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVihZczIgJKs",
        "outputId": "af9fe887-59af-46e2-f0c4-404370eed500"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
              "       'sentence_level_similarity_emotion', 'sentence_level_similarity_word',\n",
              "       'exclamation', 'PCA_MFCC_1', 'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4',\n",
              "       'PCA_MFCC_5', 'PCA_MFCC_6', 'PCA_MFCC_7', 'PCA_MFCC_8', 'PCA_W2V_1',\n",
              "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
              "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
              "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
              "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
              "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
              "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
              "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
              "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
              "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
              "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50',\n",
              "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'energy',\n",
              "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
              "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
              "       'mfccs_12', 'mfccs_13'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define all the feature columns (text + audio features)\n",
        "all_feature_columns = [\n",
        "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
        "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
        "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
        "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
        "\n",
        "# Select a subset of text features for the text-only model\n",
        "feature_columns_text = [\n",
        "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
        "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
        "\n",
        "# Select a subset of audio features for the text-only model\n",
        "feature_columns_audio = [\n",
        "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
        "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
      ],
      "metadata": {
        "id": "oTjN5HIIbAmt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target prediction\n",
        "target_column = 'sentiment_label'\n",
        "\n",
        "# Prepare the feature set and target column for both models\n",
        "X_all = df_sen[all_feature_columns]\n",
        "y = df_sen[target_column]\n",
        "\n",
        "# Function to scale, split, and apply SMOTE\n",
        "def preprocess_data(X, y):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "    return X_train_resampled, X_test, y_train_resampled, y_test"
      ],
      "metadata": {
        "id": "VPWv-BGdbB27"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Combined Model (Text + Audio Features) ---\n",
        "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)"
      ],
      "metadata": {
        "id": "BLiwRcv5bV1T"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_FCNN_new = load_model(\"model_FCNN.keras\")"
      ],
      "metadata": {
        "id": "L7nfir-CbBuH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG Boost without integrating Sarcasm Model"
      ],
      "metadata": {
        "id": "cC4JJRxGpgip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Create XGBoost DMatrix\n",
        "dtrain = xgb.DMatrix(X_train_combined, label=y_train_combined)\n",
        "dtest = xgb.DMatrix(X_test_combined, label=y_test_combined)\n",
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"logloss\",\n",
        "    \"max_depth\": 5,\n",
        "    \"n_estimators\": 10,\n",
        "    \"eta\": 0.1,\n",
        "    \"seed\": 42\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model_xgb = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "# Make predictions\n",
        "preds = model_xgb.predict(dtest)\n",
        "predictions = [1 if p > 0.5 else 0 for p in preds]\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test_combined, predictions)\n",
        "print(f\"XGBoost Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xLNqwhulKue",
        "outputId": "3d0d5782-c3a0-4bb1-aff7-cde74a73f3ca"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Accuracy: 0.5428571428571428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:28:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_combined)\n",
        "\n",
        "accuracy = accuracy_score(y_test_combined, y_pred)\n",
        "print(f\"Optimized XGBoost Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iw-6Exnfj-k",
        "outputId": "b27312d1-e865-44fb-8851-1b3886132cd0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized XGBoost Accuracy: 0.5714285714285714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG Boost with Sarcasm Model Integrated"
      ],
      "metadata": {
        "id": "Ep1HKF9rpiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
        "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
        "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
        "# Add sarcasm predictions as a new feature\n",
        "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
        "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
        "\n",
        "dtrain = xgb.DMatrix(features_with_sarcasm_train, label=y_train_combined)\n",
        "dtest = xgb.DMatrix(features_with_sarcasm_test, label=y_test_combined)\n",
        "\n",
        "model_xgb_sarcasm = xgb.train(params, dtrain, num_boost_round=100)\n",
        "preds = model_xgb_sarcasm.predict(dtest)\n",
        "predictions = [1 if p > 0.5 else 0 for p in preds]\n",
        "\n",
        "accuracy = accuracy_score(y_test_combined, predictions)\n",
        "print(f\"Updated XGBoost Model with Sarcasm Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDvfNbjcnIiv",
        "outputId": "b58c84d0-5888-4308-f13b-23c072ad2b63"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated XGBoost Model with Sarcasm Accuracy: 0.5714285714285714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:29:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FFNN without Sarcasm"
      ],
      "metadata": {
        "id": "hd4cbC-dpsqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fnn = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model_fnn.fit(X_train_combined, y_train_combined, epochs=100, batch_size=5, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model_fnn.evaluate(X_test_combined, y_test_combined)\n",
        "print(f\"FNN Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGzO9nFLo7kJ",
        "outputId": "1cbfa681-3ac8-4ae8-8509-6c55ddba3f89"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5637 - loss: 0.7566 - val_accuracy: 0.3750 - val_loss: 0.7741\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5195 - loss: 0.7116 - val_accuracy: 0.4062 - val_loss: 0.7631\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5539 - loss: 0.7320 - val_accuracy: 0.4062 - val_loss: 0.7529\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6207 - loss: 0.6641 - val_accuracy: 0.4375 - val_loss: 0.7548\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6429 - loss: 0.6436 - val_accuracy: 0.4375 - val_loss: 0.7471\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5417 - loss: 0.6751 - val_accuracy: 0.4375 - val_loss: 0.7315\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7080 - loss: 0.5771 - val_accuracy: 0.4688 - val_loss: 0.7264\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 0.6308 - val_accuracy: 0.4688 - val_loss: 0.7178\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5875 - loss: 0.6253 - val_accuracy: 0.4688 - val_loss: 0.7101\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.5388 - val_accuracy: 0.4688 - val_loss: 0.7072\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5759 - loss: 0.6443 - val_accuracy: 0.4688 - val_loss: 0.7094\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.6712 - val_accuracy: 0.5000 - val_loss: 0.7013\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6678 - loss: 0.5725 - val_accuracy: 0.5000 - val_loss: 0.6982\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 0.6002 - val_accuracy: 0.5312 - val_loss: 0.6874\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6936 - loss: 0.5459 - val_accuracy: 0.5625 - val_loss: 0.6701\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6533 - loss: 0.6300 - val_accuracy: 0.6562 - val_loss: 0.6583\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6018 - loss: 0.6336 - val_accuracy: 0.6250 - val_loss: 0.6576\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.5390 - val_accuracy: 0.6250 - val_loss: 0.6475\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6068 - loss: 0.6762 - val_accuracy: 0.6250 - val_loss: 0.6396\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7214 - loss: 0.5270 - val_accuracy: 0.6250 - val_loss: 0.6381\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6443 - loss: 0.5503 - val_accuracy: 0.6562 - val_loss: 0.6368\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6292 - loss: 0.5619 - val_accuracy: 0.6562 - val_loss: 0.6368\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6103 - loss: 0.5842 - val_accuracy: 0.6250 - val_loss: 0.6410\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 0.5429 - val_accuracy: 0.6250 - val_loss: 0.6331\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4794 - val_accuracy: 0.6250 - val_loss: 0.6295\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.5757 - val_accuracy: 0.6562 - val_loss: 0.6159\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.5408 - val_accuracy: 0.6875 - val_loss: 0.5996\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6993 - loss: 0.5652 - val_accuracy: 0.7500 - val_loss: 0.5908\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6656 - loss: 0.5262 - val_accuracy: 0.7188 - val_loss: 0.5888\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6385 - loss: 0.5466 - val_accuracy: 0.7188 - val_loss: 0.5870\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 0.5870 - val_accuracy: 0.7188 - val_loss: 0.5800\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6540 - loss: 0.5507 - val_accuracy: 0.7188 - val_loss: 0.5805\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6688 - loss: 0.5012 - val_accuracy: 0.7188 - val_loss: 0.5704\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7414 - loss: 0.4639 - val_accuracy: 0.7500 - val_loss: 0.5599\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7123 - loss: 0.4739 - val_accuracy: 0.7500 - val_loss: 0.5641\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6002 - loss: 0.5901 - val_accuracy: 0.7500 - val_loss: 0.5591\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7322 - loss: 0.5094 - val_accuracy: 0.7500 - val_loss: 0.5614\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 0.5353 - val_accuracy: 0.7500 - val_loss: 0.5562\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6879 - loss: 0.5606 - val_accuracy: 0.7500 - val_loss: 0.5565\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7270 - loss: 0.5171 - val_accuracy: 0.7812 - val_loss: 0.5411\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.4620 - val_accuracy: 0.7500 - val_loss: 0.5447\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6688 - loss: 0.5776 - val_accuracy: 0.7188 - val_loss: 0.5526\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4478 - val_accuracy: 0.7188 - val_loss: 0.5426\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 0.4744 - val_accuracy: 0.7188 - val_loss: 0.5250\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7836 - loss: 0.4283 - val_accuracy: 0.7188 - val_loss: 0.5192\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.4987 - val_accuracy: 0.7188 - val_loss: 0.5269\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.4413 - val_accuracy: 0.7188 - val_loss: 0.5257\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.3557 - val_accuracy: 0.7500 - val_loss: 0.5091\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 0.4041 - val_accuracy: 0.7500 - val_loss: 0.5030\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.4206 - val_accuracy: 0.7500 - val_loss: 0.4994\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7580 - loss: 0.4973 - val_accuracy: 0.7812 - val_loss: 0.4880\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8234 - loss: 0.4085 - val_accuracy: 0.7812 - val_loss: 0.4911\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4227 - val_accuracy: 0.7812 - val_loss: 0.4849\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.3908 - val_accuracy: 0.8125 - val_loss: 0.4700\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.4461 - val_accuracy: 0.7812 - val_loss: 0.4701\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.3657 - val_accuracy: 0.7812 - val_loss: 0.4848\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4559 - val_accuracy: 0.7500 - val_loss: 0.4751\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.4052 - val_accuracy: 0.8125 - val_loss: 0.4637\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.3747 - val_accuracy: 0.7812 - val_loss: 0.4724\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.3184 - val_accuracy: 0.8125 - val_loss: 0.4498\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.4144 - val_accuracy: 0.8125 - val_loss: 0.4587\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.4308 - val_accuracy: 0.7812 - val_loss: 0.4565\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 0.3467 - val_accuracy: 0.7812 - val_loss: 0.4531\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.4066 - val_accuracy: 0.7812 - val_loss: 0.4471\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4614 - val_accuracy: 0.7500 - val_loss: 0.4640\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.4421 - val_accuracy: 0.7812 - val_loss: 0.4557\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8631 - loss: 0.3672 - val_accuracy: 0.7188 - val_loss: 0.4722\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.3335 - val_accuracy: 0.7188 - val_loss: 0.4704\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8118 - loss: 0.3826 - val_accuracy: 0.7500 - val_loss: 0.4556\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8504 - loss: 0.3197 - val_accuracy: 0.7500 - val_loss: 0.4641\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8663 - loss: 0.3235 - val_accuracy: 0.7500 - val_loss: 0.4666\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9410 - loss: 0.2916 - val_accuracy: 0.7500 - val_loss: 0.4631\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8492 - loss: 0.3535 - val_accuracy: 0.7500 - val_loss: 0.4599\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8604 - loss: 0.3157 - val_accuracy: 0.7500 - val_loss: 0.4563\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7019 - loss: 0.4853 - val_accuracy: 0.7188 - val_loss: 0.4609\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.4303 - val_accuracy: 0.7500 - val_loss: 0.4645\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8747 - loss: 0.2874 - val_accuracy: 0.7188 - val_loss: 0.4592\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.3772 - val_accuracy: 0.7812 - val_loss: 0.4452\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8872 - loss: 0.2758 - val_accuracy: 0.7812 - val_loss: 0.4432\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8752 - loss: 0.3381 - val_accuracy: 0.7500 - val_loss: 0.4605\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8624 - loss: 0.3904 - val_accuracy: 0.7812 - val_loss: 0.4636\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3463 - val_accuracy: 0.7500 - val_loss: 0.4595\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.3151 - val_accuracy: 0.7500 - val_loss: 0.4620\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8934 - loss: 0.2890 - val_accuracy: 0.7500 - val_loss: 0.4705\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 0.3485 - val_accuracy: 0.7812 - val_loss: 0.4624\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.3908 - val_accuracy: 0.8125 - val_loss: 0.4564\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.3770 - val_accuracy: 0.8438 - val_loss: 0.4364\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.3240 - val_accuracy: 0.7812 - val_loss: 0.4377\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8617 - loss: 0.3022 - val_accuracy: 0.8125 - val_loss: 0.4362\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9078 - loss: 0.2682 - val_accuracy: 0.7812 - val_loss: 0.4545\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.3605 - val_accuracy: 0.7812 - val_loss: 0.4652\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.3380 - val_accuracy: 0.7812 - val_loss: 0.4738\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2780 - val_accuracy: 0.7500 - val_loss: 0.4835\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.3148 - val_accuracy: 0.7500 - val_loss: 0.4906\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.3446 - val_accuracy: 0.7500 - val_loss: 0.5001\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4253 - val_accuracy: 0.7812 - val_loss: 0.4996\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.2910 - val_accuracy: 0.7812 - val_loss: 0.4869\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3190 - val_accuracy: 0.7812 - val_loss: 0.4704\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.2245 - val_accuracy: 0.7812 - val_loss: 0.4672\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2168 - val_accuracy: 0.8125 - val_loss: 0.5017\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5979 - loss: 0.9636\n",
            "FNN Model Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FFNN with Sarcasm"
      ],
      "metadata": {
        "id": "JiHTR4mArbte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
        "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
        "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
        "# Add sarcasm predictions as a new feature\n",
        "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
        "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
        "\n",
        "model_fnn = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=(features_with_sarcasm_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model_fnn.fit(features_with_sarcasm_train, y_train_combined, epochs=100, batch_size=5, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model_fnn.evaluate(features_with_sarcasm_test, y_test_combined)\n",
        "print(f\"FNN Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwLrgMnNrOxl",
        "outputId": "d2fe7ed4-d11e-4668-f877-f92ab968f2a4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5682 - loss: 0.7286 - val_accuracy: 0.3125 - val_loss: 0.7493\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5842 - loss: 0.7023 - val_accuracy: 0.3125 - val_loss: 0.7352\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4946 - loss: 0.7477 - val_accuracy: 0.3438 - val_loss: 0.7189\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5546 - loss: 0.6644 - val_accuracy: 0.3438 - val_loss: 0.7157\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6323 - loss: 0.6186 - val_accuracy: 0.3750 - val_loss: 0.7083\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4990 - loss: 0.6959 - val_accuracy: 0.4062 - val_loss: 0.6949\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5833 - loss: 0.7114 - val_accuracy: 0.5312 - val_loss: 0.6761\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7100 - loss: 0.5985 - val_accuracy: 0.4688 - val_loss: 0.6747\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5971 - loss: 0.6215 - val_accuracy: 0.4688 - val_loss: 0.6688\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6063 - loss: 0.6487 - val_accuracy: 0.5000 - val_loss: 0.6635\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5774 - loss: 0.6360 - val_accuracy: 0.5000 - val_loss: 0.6631\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6680 - loss: 0.6018 - val_accuracy: 0.5000 - val_loss: 0.6545\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6602 - loss: 0.5792 - val_accuracy: 0.5000 - val_loss: 0.6555\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6814 - loss: 0.5729 - val_accuracy: 0.5312 - val_loss: 0.6403\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5862 - loss: 0.6144 - val_accuracy: 0.5312 - val_loss: 0.6373\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7300 - loss: 0.5458 - val_accuracy: 0.5312 - val_loss: 0.6385\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 0.5004 - val_accuracy: 0.5312 - val_loss: 0.6289\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5871 - loss: 0.5929 - val_accuracy: 0.5625 - val_loss: 0.6267\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.5712 - val_accuracy: 0.5625 - val_loss: 0.6280\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 0.5497 - val_accuracy: 0.6562 - val_loss: 0.6211\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 0.5849 - val_accuracy: 0.6562 - val_loss: 0.6160\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7162 - loss: 0.5895 - val_accuracy: 0.6562 - val_loss: 0.6126\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.5678 - val_accuracy: 0.6562 - val_loss: 0.6186\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6410 - loss: 0.5663 - val_accuracy: 0.6875 - val_loss: 0.6163\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6791 - loss: 0.5450 - val_accuracy: 0.6875 - val_loss: 0.6152\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6689 - loss: 0.5638 - val_accuracy: 0.6875 - val_loss: 0.6095\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.4724 - val_accuracy: 0.6875 - val_loss: 0.6029\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6579 - loss: 0.5434 - val_accuracy: 0.7188 - val_loss: 0.5977\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.4832 - val_accuracy: 0.7188 - val_loss: 0.5942\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7138 - loss: 0.5227 - val_accuracy: 0.6875 - val_loss: 0.5877\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7207 - loss: 0.5050 - val_accuracy: 0.7188 - val_loss: 0.5816\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.5329 - val_accuracy: 0.6875 - val_loss: 0.5798\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.5235 - val_accuracy: 0.7188 - val_loss: 0.5789\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4330 - val_accuracy: 0.6875 - val_loss: 0.5730\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.4562 - val_accuracy: 0.7188 - val_loss: 0.5622\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.5383 - val_accuracy: 0.6875 - val_loss: 0.5534\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7911 - loss: 0.4508 - val_accuracy: 0.7188 - val_loss: 0.5484\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4125 - val_accuracy: 0.7500 - val_loss: 0.5313\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.5562 - val_accuracy: 0.7812 - val_loss: 0.5228\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7531 - loss: 0.5403 - val_accuracy: 0.7500 - val_loss: 0.5310\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.5412 - val_accuracy: 0.7500 - val_loss: 0.5357\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.4053 - val_accuracy: 0.7188 - val_loss: 0.5335\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4515 - val_accuracy: 0.7812 - val_loss: 0.5314\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7798 - loss: 0.4321 - val_accuracy: 0.7812 - val_loss: 0.5209\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.5208 - val_accuracy: 0.7812 - val_loss: 0.5182\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.4721 - val_accuracy: 0.7812 - val_loss: 0.5194\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.4388 - val_accuracy: 0.8125 - val_loss: 0.5223\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.4254 - val_accuracy: 0.7500 - val_loss: 0.5184\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.4651 - val_accuracy: 0.8125 - val_loss: 0.5104\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7608 - loss: 0.4478 - val_accuracy: 0.8125 - val_loss: 0.4986\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.4755 - val_accuracy: 0.8125 - val_loss: 0.4948\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7592 - loss: 0.4787 - val_accuracy: 0.8125 - val_loss: 0.4913\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.4236 - val_accuracy: 0.8125 - val_loss: 0.4870\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.4436 - val_accuracy: 0.8438 - val_loss: 0.4986\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4028 - val_accuracy: 0.8125 - val_loss: 0.4908\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3991 - val_accuracy: 0.8750 - val_loss: 0.4921\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.3867 - val_accuracy: 0.8750 - val_loss: 0.4901\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 0.4388 - val_accuracy: 0.8438 - val_loss: 0.4875\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.4329 - val_accuracy: 0.8438 - val_loss: 0.4778\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.3771 - val_accuracy: 0.8438 - val_loss: 0.4807\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 0.3685 - val_accuracy: 0.8438 - val_loss: 0.4910\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8343 - loss: 0.4015 - val_accuracy: 0.8125 - val_loss: 0.4919\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.3650 - val_accuracy: 0.8125 - val_loss: 0.4821\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.3585 - val_accuracy: 0.8125 - val_loss: 0.4693\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.4880 - val_accuracy: 0.8438 - val_loss: 0.4717\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.3729 - val_accuracy: 0.8438 - val_loss: 0.4654\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.3485 - val_accuracy: 0.8125 - val_loss: 0.4694\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.4590 - val_accuracy: 0.7812 - val_loss: 0.4721\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3376 - val_accuracy: 0.7812 - val_loss: 0.4681\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.3898 - val_accuracy: 0.8125 - val_loss: 0.4574\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.3172 - val_accuracy: 0.8438 - val_loss: 0.4488\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.2974 - val_accuracy: 0.7812 - val_loss: 0.4563\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3332 - val_accuracy: 0.8438 - val_loss: 0.4393\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3543 - val_accuracy: 0.8438 - val_loss: 0.4284\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.3736 - val_accuracy: 0.8438 - val_loss: 0.4354\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 0.3763 - val_accuracy: 0.8125 - val_loss: 0.4502\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8522 - loss: 0.4224 - val_accuracy: 0.8125 - val_loss: 0.4573\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8296 - loss: 0.3952 - val_accuracy: 0.8125 - val_loss: 0.4710\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7599 - loss: 0.4412 - val_accuracy: 0.7812 - val_loss: 0.4752\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3525 - val_accuracy: 0.7812 - val_loss: 0.4700\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9221 - loss: 0.3215 - val_accuracy: 0.7812 - val_loss: 0.4659\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8634 - loss: 0.3400 - val_accuracy: 0.7812 - val_loss: 0.4635\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8637 - loss: 0.3780 - val_accuracy: 0.7812 - val_loss: 0.4699\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8630 - loss: 0.3466 - val_accuracy: 0.8125 - val_loss: 0.4704\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8867 - loss: 0.3008 - val_accuracy: 0.7500 - val_loss: 0.4764\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8986 - loss: 0.2997 - val_accuracy: 0.7812 - val_loss: 0.4704\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.3220 - val_accuracy: 0.7812 - val_loss: 0.4799\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.3285 - val_accuracy: 0.7812 - val_loss: 0.4835\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.2610 - val_accuracy: 0.7812 - val_loss: 0.4693\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 0.3104 - val_accuracy: 0.7812 - val_loss: 0.4700\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.2920 - val_accuracy: 0.7812 - val_loss: 0.4637\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9082 - loss: 0.2247 - val_accuracy: 0.7500 - val_loss: 0.4705\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9314 - loss: 0.2226 - val_accuracy: 0.7812 - val_loss: 0.4662\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.2799 - val_accuracy: 0.8125 - val_loss: 0.4661\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.3091 - val_accuracy: 0.8125 - val_loss: 0.4779\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2665 - val_accuracy: 0.7812 - val_loss: 0.4898\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.1971 - val_accuracy: 0.8125 - val_loss: 0.4945\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9115 - loss: 0.2436 - val_accuracy: 0.8125 - val_loss: 0.5035\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.2806 - val_accuracy: 0.8125 - val_loss: 0.4963\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3416 - val_accuracy: 0.7812 - val_loss: 0.5054\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6274 - loss: 0.8770\n",
            "FNN Model Accuracy: 0.6285714507102966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM without Sarcasm"
      ],
      "metadata": {
        "id": "qzEW1dpCzwvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Predict with SVM\n",
        "y_pred_svm = svm_model.predict(X_test_combined)\n",
        "# Calculate probabilities for SVM\n",
        "y_pred_svm_proba = svm_model.decision_function(X_test_combined)  # For SVM, use decision_function for Precision-Recall\n",
        "\n",
        "\n",
        "# Evaluate SVM Model\n",
        "print(\"\\nSupport Vector Machine (SVM) Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_svm):.2f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqD91-ZpsarR",
        "outputId": "9fa75edf-2029-4a58-aa9d-2aa2abd05cca"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Support Vector Machine (SVM) Results:\n",
            "Accuracy: 0.51\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.55      0.56        20\n",
            "           1       0.44      0.47      0.45        15\n",
            "\n",
            "    accuracy                           0.51        35\n",
            "   macro avg       0.51      0.51      0.51        35\n",
            "weighted avg       0.52      0.51      0.52        35\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1Q4nUR2z0sP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}