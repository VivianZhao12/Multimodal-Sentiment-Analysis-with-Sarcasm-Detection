{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmZ7TT_ZX1QF",
    "outputId": "71cb8974-92ab-4c8d-9c0b-8e63c051f832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Multimodal-Sentiment-Analysis-with-Sarcasm-Detection' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/VivianZhao12/Multimodal-Sentiment-Analysis-with-Sarcasm-Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YklIVwNqY2TS"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import scikitplot as skplt\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC  # Importing Support Vector Classifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # For oversampling\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization, Layer, Softmax, Activation, Conv1D, MaxPooling1D, Flatten, LSTM, InputLayer\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou6odKSvaI7S",
    "outputId": "0234a9f3-73e8-4d60-de9c-e875a8989086"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
       "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'PCA_MFCC_1',\n",
       "       'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4', 'PCA_MFCC_5', 'PCA_MFCC_6',\n",
       "       'PCA_MFCC_7', 'PCA_MFCC_8', 'sentence_level_similarity_emotion',\n",
       "       'sentence_level_similarity_word', 'exclamation', 'PCA_W2V_1',\n",
       "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
       "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
       "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
       "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
       "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
       "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
       "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
       "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
       "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
       "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50', 'PCA_W2V_51',\n",
       "       'PCA_W2V_52', 'PCA_W2V_53', 'PCA_W2V_54', 'PCA_W2V_55', 'PCA_W2V_56',\n",
       "       'PCA_W2V_57', 'PCA_W2V_58', 'PCA_W2V_59', 'PCA_W2V_60', 'energy',\n",
       "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
       "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
       "       'mfccs_12', 'mfccs_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sar = pd.read_csv('../datasets/sarcasm_final.csv')\n",
    "df_sar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s-Y7O8-qaK-X"
   },
   "outputs": [],
   "source": [
    "# Define all the feature columns (text + audio features)\n",
    "all_feature_columns = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of text features for the text-only model\n",
    "feature_columns_text = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of audio features for the text-only model\n",
    "feature_columns_audio = [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nSSkvQaIaN2a"
   },
   "outputs": [],
   "source": [
    "# target prediction\n",
    "target_column = 'sarcasm_label'\n",
    "\n",
    "# Prepare the feature set and target column for both models\n",
    "X_all = df_sar[all_feature_columns]\n",
    "y = df_sar[target_column]\n",
    "\n",
    "# Function to scale, split, and apply SMOTE\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test\n",
    "\n",
    "# --- Text-Only Model ---\n",
    "X_text = df_sar[feature_columns_text]\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = preprocess_data(X_text, y)\n",
    "\n",
    "# --- Audio-Only Model --- this is for following hybrid model\n",
    "X_audio = df_sar[feature_columns_audio]\n",
    "X_train_audio, X_test_audio, y_train_audio, y_test_audio = preprocess_data(X_audio, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tBrkqKBTaQTW"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with text features\n",
    "logistic_model_text = LogisticRegression(max_iter=500, random_state=42)\n",
    "logistic_model_text.fit(X_train_text, y_train_text)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_text = logistic_model_text.predict(X_test_text)\n",
    "\n",
    "# --- Combined Model (Text + Audio Features) ---\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)\n",
    "\n",
    "# Logistic Regression with both text and audio features\n",
    "logistic_model_combined = LogisticRegression(max_iter=500, random_state=42)\n",
    "logistic_model_combined.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_combined = logistic_model_combined.predict(X_test_combined)\n",
    "y_pred_logistic_proba = logistic_model_combined.decision_function(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a9jo2MlZdIlX"
   },
   "outputs": [],
   "source": [
    "# Evaluation Results (Text-Only Model)\n",
    "accuracy_text = accuracy_score(y_test_text, y_pred_text)\n",
    "cm_text = confusion_matrix(y_test_text, y_pred_text)\n",
    "cr_text = classification_report(y_test_text, y_pred_text, output_dict=True)\n",
    "\n",
    "# Evaluation Results (Combined Model)\n",
    "accuracy_combined = accuracy_score(y_test_combined, y_pred_combined)\n",
    "cm_combined = confusion_matrix(y_test_combined, y_pred_combined)\n",
    "cr_combined = classification_report(y_test_combined, y_pred_combined, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31wMFz4rdOiD",
    "outputId": "f7913b40-798a-4569-fc38-7be26355bcfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.318500\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_text.columns contains the correct feature names\n",
    "feature_names = ['Intercept'] + list(X_all.columns)\n",
    "\n",
    "# Add an intercept to the combined dataset\n",
    "X_train_combined_with_intercept = sm.add_constant(X_train_combined)\n",
    "\n",
    "# Fit the logistic regression model using statsmodels\n",
    "logit_model = sm.Logit(y_train_combined, X_train_combined_with_intercept)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Convert the result summary to a DataFrame and replace the index with feature names\n",
    "summary_table = result.summary2().tables[1]  # Get the coefficient table\n",
    "summary_table.index = feature_names  # Replace generic 'x1', 'x2', ... with actual names\n",
    "\n",
    "sorted_summary = summary_table.sort_values(by='P>|z|')\n",
    "\n",
    "# Identify significant features based on p-value\n",
    "significant_features = summary_table[summary_table['P>|z|'] < 0.01]\n",
    "\n",
    "# Sort significant features by the absolute value of their coefficients\n",
    "significant_features_sorted = significant_features.reindex(\n",
    "    significant_features['Coef.'].abs().sort_values(ascending=False).index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "604qfkNTdT6c",
    "outputId": "09c9e3f4-8908-4732-9e65-8ad92eacc17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine (SVM) Results:\n",
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85        38\n",
      "           1       0.59      0.71      0.65        14\n",
      "\n",
      "    accuracy                           0.79        52\n",
      "   macro avg       0.74      0.77      0.75        52\n",
      "weighted avg       0.81      0.79      0.79        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM) Model\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict with SVM\n",
    "y_pred_svm = svm_model.predict(X_test_combined)\n",
    "# Calculate probabilities for SVM\n",
    "y_pred_svm_proba = svm_model.decision_function(X_test_combined)  # For SVM, use decision_function for Precision-Recall\n",
    "\n",
    "\n",
    "# Evaluate SVM Model\n",
    "print(\"\\nSupport Vector Machine (SVM) Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_svm):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-U3spqQdYGE",
    "outputId": "fb5a2cbb-3c6e-4e97-bac2-38b751f8d362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.77\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83        38\n",
      "           1       0.55      0.79      0.65        14\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.73      0.77      0.74        52\n",
      "weighted avg       0.81      0.77      0.78        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_combined, y_train_combined)\n",
    "y_pred_nb_proba = nb_model.predict(X_test_combined)\n",
    "\n",
    "# Evaluate Naive Bayes Model\n",
    "print(\"\\nNaive Bayes Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_nb_proba):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_nb_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7dbX8OudbnD",
    "outputId": "d69a23f8-c51b-457e-ed52-c632a75ef457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.81\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        38\n",
      "           1       0.67      0.57      0.62        14\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.76      0.73      0.74        52\n",
      "weighted avg       0.80      0.81      0.80        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "clf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_clf = clf_model.predict(X_test_combined)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy_clf = accuracy_score(y_test_combined, y_pred_clf)\n",
    "\n",
    "# Generating a classification report\n",
    "class_report = classification_report(y_test_combined, y_pred_clf)\n",
    "\n",
    "# Printing out the results\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_clf:.2f}\")\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dEcG1bldhrT",
    "outputId": "4c408d50-b9da-4732-8240-426bd9b79ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.77\n",
      "SVM Accuracy: 0.79\n",
      "Naive Bayes Accuracy: 0.77\n",
      "Random Forest Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracies for each model\n",
    "accuracy_logistic = logistic_model_combined.score(X_test_combined, y_test_combined)\n",
    "accuracy_svm = svm_model.score(X_test_combined, y_test_combined)\n",
    "accuracy_nb = nb_model.score(X_test_combined, y_test_combined)\n",
    "\n",
    "# Print accuracy values\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.2f}\")\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb:.2f}\")\n",
    "print(f\"Random Forest Accuracy: {accuracy_clf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BqTuKbQedjKz"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Precision-Recall\n",
    "precision_logistic, recall_logistic, _ = precision_recall_curve(y_test_combined, y_pred_logistic_proba)\n",
    "pr_auc_logistic = auc(recall_logistic, precision_logistic)\n",
    "\n",
    "# SVM Precision-Recall\n",
    "precision_svm, recall_svm, _ = precision_recall_curve(y_test_combined, y_pred_svm_proba)\n",
    "pr_auc_svm = auc(recall_svm, precision_svm)\n",
    "\n",
    "# Naive Bayes Precision-Recall\n",
    "precision_nb, recall_nb, _ = precision_recall_curve(y_test_combined, y_pred_nb_proba)\n",
    "pr_auc_nb = auc(recall_nb, precision_nb)\n",
    "\n",
    "# Assuming clf_rf is your trained Random Forest classifier\n",
    "y_pred_rf_proba = clf_model.predict_proba(X_test_combined)[:, 1]\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test_combined, y_pred_rf_proba)\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)\n",
    "\n",
    "# Compute ROC curves and AUC scores\n",
    "fpr_logistic, tpr_logistic, _ = roc_curve(y_test_combined, y_pred_logistic_proba)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test_combined, y_pred_nb_proba)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test_combined, y_pred_svm_proba)\n",
    "\n",
    "auc_logistic = roc_auc_score(y_test_combined, y_pred_logistic_proba)\n",
    "auc_svm = roc_auc_score(y_test_combined, y_pred_svm_proba)\n",
    "auc_nb = roc_auc_score(y_test_combined, y_pred_nb_proba)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_combined, y_pred_rf_proba)\n",
    "auc_rf = roc_auc_score(y_test_combined, y_pred_rf_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAofh4z4dn77",
    "outputId": "f2688be3-785a-4507-c321-d6e873f5febf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 136ms/step - accuracy: 0.5851 - loss: 0.6845 - val_accuracy: 0.0167 - val_loss: 0.8102\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5604 - loss: 0.6930 - val_accuracy: 0.0500 - val_loss: 0.8005\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6461 - loss: 0.5887 - val_accuracy: 0.1333 - val_loss: 0.7831\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6502 - loss: 0.6126 - val_accuracy: 0.4167 - val_loss: 0.7517\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5983 - loss: 0.6396 - val_accuracy: 0.5833 - val_loss: 0.7159\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6498 - loss: 0.5753 - val_accuracy: 0.7667 - val_loss: 0.6757\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7206 - loss: 0.5669 - val_accuracy: 0.8000 - val_loss: 0.6513\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7191 - loss: 0.5607 - val_accuracy: 0.8167 - val_loss: 0.6200\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7102 - loss: 0.5372 - val_accuracy: 0.8500 - val_loss: 0.5917\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7715 - loss: 0.5047 - val_accuracy: 0.8500 - val_loss: 0.5600\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7597 - loss: 0.5110 - val_accuracy: 0.8500 - val_loss: 0.5354\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7376 - loss: 0.4777 - val_accuracy: 0.8667 - val_loss: 0.5069\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7657 - loss: 0.4735 - val_accuracy: 0.8833 - val_loss: 0.4801\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7687 - loss: 0.5167 - val_accuracy: 0.8833 - val_loss: 0.4604\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7903 - loss: 0.4858 - val_accuracy: 0.8833 - val_loss: 0.4421\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8078 - loss: 0.4227 - val_accuracy: 0.8833 - val_loss: 0.4248\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8150 - loss: 0.4384 - val_accuracy: 0.8833 - val_loss: 0.4175\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7626 - loss: 0.4738 - val_accuracy: 0.9000 - val_loss: 0.4064\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8096 - loss: 0.4510 - val_accuracy: 0.9000 - val_loss: 0.3825\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8340 - loss: 0.4046 - val_accuracy: 0.9333 - val_loss: 0.3604\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8225 - loss: 0.4322 - val_accuracy: 0.9333 - val_loss: 0.3441\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8215 - loss: 0.3886 - val_accuracy: 0.9333 - val_loss: 0.3256\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8182 - loss: 0.3927 - val_accuracy: 0.9333 - val_loss: 0.3144\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8607 - loss: 0.3656 - val_accuracy: 0.9333 - val_loss: 0.3027\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7754 - loss: 0.4299 - val_accuracy: 0.9333 - val_loss: 0.3001\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7902 - loss: 0.4207 - val_accuracy: 0.9333 - val_loss: 0.2992\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8312 - loss: 0.3750 - val_accuracy: 0.9333 - val_loss: 0.3011\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8392 - loss: 0.3162 - val_accuracy: 0.9333 - val_loss: 0.3002\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8275 - loss: 0.3873 - val_accuracy: 0.9333 - val_loss: 0.2926\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8206 - loss: 0.3834 - val_accuracy: 0.9333 - val_loss: 0.2848\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7747 - loss: 0.4080 - val_accuracy: 0.9333 - val_loss: 0.2841\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8343 - loss: 0.3424 - val_accuracy: 0.9333 - val_loss: 0.2753\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8238 - loss: 0.3685 - val_accuracy: 0.9333 - val_loss: 0.2652\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8569 - loss: 0.3580 - val_accuracy: 0.9333 - val_loss: 0.2584\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8202 - loss: 0.3685 - val_accuracy: 0.9333 - val_loss: 0.2507\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8705 - loss: 0.3306 - val_accuracy: 0.9333 - val_loss: 0.2434\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8489 - loss: 0.3149 - val_accuracy: 0.9167 - val_loss: 0.2368\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8476 - loss: 0.2965 - val_accuracy: 0.9333 - val_loss: 0.2276\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8771 - loss: 0.3310 - val_accuracy: 0.9333 - val_loss: 0.2220\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8490 - loss: 0.3381 - val_accuracy: 0.9333 - val_loss: 0.2184\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8799 - loss: 0.3086 - val_accuracy: 0.9333 - val_loss: 0.2125\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8694 - loss: 0.3015 - val_accuracy: 0.9333 - val_loss: 0.2151\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8979 - loss: 0.2996 - val_accuracy: 0.9333 - val_loss: 0.2108\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8209 - loss: 0.3374 - val_accuracy: 0.9333 - val_loss: 0.2080\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8891 - loss: 0.3053 - val_accuracy: 0.9333 - val_loss: 0.2022\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8800 - loss: 0.2407 - val_accuracy: 0.9333 - val_loss: 0.1908\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.3361 - val_accuracy: 0.9333 - val_loss: 0.1825\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8796 - loss: 0.3031 - val_accuracy: 0.9333 - val_loss: 0.1861\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8484 - loss: 0.3399 - val_accuracy: 0.9333 - val_loss: 0.1916\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.2627 - val_accuracy: 0.9333 - val_loss: 0.1917\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8221 - loss: 0.4752 \n",
      "FCNN Accuracy: 0.8269230723381042\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Ensuring the same random seed is used every time before any layer weights are initialized\n",
    "# Build a full connect neural network\n",
    "model_FCNN = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_FCNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_FCNN.fit(X_train_combined, y_train_combined, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "fcnn_loss, fcnn_accuracy = model_FCNN.evaluate(X_test_combined, y_test_combined)\n",
    "print(f'FCNN Accuracy: {fcnn_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "f_an5vJ9faB8"
   },
   "outputs": [],
   "source": [
    "model_FCNN.save(\"model_FCNN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14OYeL6od-in",
    "outputId": "69075722-37d3-4790-b556-257d9c416f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.5478 - loss: 1.6533 - val_accuracy: 0.0500 - val_loss: 1.6955\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5885 - loss: 1.5467 - val_accuracy: 0.3500 - val_loss: 1.6234\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7010 - loss: 1.4232 - val_accuracy: 0.6667 - val_loss: 1.5498\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7476 - loss: 1.4069 - val_accuracy: 0.8000 - val_loss: 1.4839\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7208 - loss: 1.3477 - val_accuracy: 0.8667 - val_loss: 1.4236\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7443 - loss: 1.2948 - val_accuracy: 0.9000 - val_loss: 1.3587\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7943 - loss: 1.2591 - val_accuracy: 0.9167 - val_loss: 1.3038\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8329 - loss: 1.1972 - val_accuracy: 0.9333 - val_loss: 1.2512\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8320 - loss: 1.1769 - val_accuracy: 0.9333 - val_loss: 1.1992\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8062 - loss: 1.1386 - val_accuracy: 0.9333 - val_loss: 1.1480\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8285 - loss: 1.0865 - val_accuracy: 0.9333 - val_loss: 1.1056\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8219 - loss: 1.0730 - val_accuracy: 0.9333 - val_loss: 1.0681\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8561 - loss: 1.0007 - val_accuracy: 0.9333 - val_loss: 1.0314\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8433 - loss: 1.0054 - val_accuracy: 0.9333 - val_loss: 0.9948\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.9978 - val_accuracy: 0.9333 - val_loss: 0.9619\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8383 - loss: 0.9309 - val_accuracy: 0.9333 - val_loss: 0.9267\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8230 - loss: 0.9465 - val_accuracy: 0.9333 - val_loss: 0.8993\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8326 - loss: 0.9194 - val_accuracy: 0.9333 - val_loss: 0.8750\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8573 - loss: 0.8756 - val_accuracy: 0.9333 - val_loss: 0.8472\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8865 - loss: 0.8100 - val_accuracy: 0.9333 - val_loss: 0.8171\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8937 - loss: 0.8145 - val_accuracy: 0.9333 - val_loss: 0.7879\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8640 - loss: 0.7737 - val_accuracy: 0.9333 - val_loss: 0.7607\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8797 - loss: 0.7848 - val_accuracy: 0.9333 - val_loss: 0.7376\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8939 - loss: 0.7261 - val_accuracy: 0.9333 - val_loss: 0.7165\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9178 - loss: 0.7095 - val_accuracy: 0.9333 - val_loss: 0.6984\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8543 - loss: 0.7420 - val_accuracy: 0.9333 - val_loss: 0.6765\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8907 - loss: 0.6619 - val_accuracy: 0.9333 - val_loss: 0.6606\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9176 - loss: 0.6471 - val_accuracy: 0.9333 - val_loss: 0.6475\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8711 - loss: 0.6617 - val_accuracy: 0.9333 - val_loss: 0.6324\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9222 - loss: 0.6183 - val_accuracy: 0.9333 - val_loss: 0.6189\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9071 - loss: 0.6233 - val_accuracy: 0.9333 - val_loss: 0.6080\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9193 - loss: 0.5876 - val_accuracy: 0.9333 - val_loss: 0.5939\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9359 - loss: 0.5720 - val_accuracy: 0.9333 - val_loss: 0.5789\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9157 - loss: 0.5768 - val_accuracy: 0.9500 - val_loss: 0.5603\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.5547 - val_accuracy: 0.9500 - val_loss: 0.5418\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9194 - loss: 0.5104 - val_accuracy: 0.9500 - val_loss: 0.5254\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9362 - loss: 0.5216 - val_accuracy: 0.9500 - val_loss: 0.5100\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9469 - loss: 0.4744 - val_accuracy: 0.9500 - val_loss: 0.4923\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9202 - loss: 0.5006 - val_accuracy: 0.9500 - val_loss: 0.4801\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9260 - loss: 0.5030 - val_accuracy: 0.9500 - val_loss: 0.4716\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9159 - loss: 0.5056 - val_accuracy: 0.9500 - val_loss: 0.4681\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.4312 - val_accuracy: 0.9500 - val_loss: 0.4625\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9448 - loss: 0.4642 - val_accuracy: 0.9500 - val_loss: 0.4497\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9522 - loss: 0.4543 - val_accuracy: 0.9500 - val_loss: 0.4379\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.4153 - val_accuracy: 0.9500 - val_loss: 0.4278\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9712 - loss: 0.3871 - val_accuracy: 0.9500 - val_loss: 0.4109\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9496 - loss: 0.4154 - val_accuracy: 0.9500 - val_loss: 0.3952\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9511 - loss: 0.3906 - val_accuracy: 0.9500 - val_loss: 0.3895\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9429 - loss: 0.3884 - val_accuracy: 0.9500 - val_loss: 0.3920\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9577 - loss: 0.3707 - val_accuracy: 0.9500 - val_loss: 0.3820\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7628 - loss: 0.7504 \n",
      "Enhanced FCNN Model Accuracy: 0.7692307829856873\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Build a more robust fully connected neural network\n",
    "model_ehFCNN = Sequential([\n",
    "    InputLayer(input_shape=(X_train_combined.shape[1],)),\n",
    "\n",
    "    Dense(64, kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Optimizer with a learning rate schedule\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model_ehFCNN.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and saving the best model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model with validation split and callbacks\n",
    "history = model_ehFCNN.fit(\n",
    "    X_train_combined,\n",
    "    y_train_combined,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "fcnn_loss, fcnn_accuracy = model_ehFCNN.evaluate(X_test_combined, y_test_combined)\n",
    "print(f'Enhanced FCNN Model Accuracy: {fcnn_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxM5v5GkYCZT",
    "outputId": "d3cbe829-8528-4d57-9192-67491bb2ac88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6228 - loss: 2.2666 - val_accuracy: 0.7308 - val_loss: 2.0007\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8281 - loss: 1.7813 - val_accuracy: 0.7500 - val_loss: 1.8690\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8478 - loss: 1.6895 - val_accuracy: 0.7692 - val_loss: 1.7872\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8988 - loss: 1.5809 - val_accuracy: 0.7885 - val_loss: 1.7248\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8794 - loss: 1.4910 - val_accuracy: 0.7692 - val_loss: 1.6694\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8331 - loss: 1.5130 - val_accuracy: 0.7308 - val_loss: 1.6226\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8981 - loss: 1.3866 - val_accuracy: 0.7500 - val_loss: 1.5783\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9277 - loss: 1.3058 - val_accuracy: 0.7308 - val_loss: 1.5295\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9510 - loss: 1.2018 - val_accuracy: 0.7692 - val_loss: 1.4858\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8961 - loss: 1.2225 - val_accuracy: 0.7500 - val_loss: 1.4326\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9065 - loss: 1.1635 - val_accuracy: 0.7308 - val_loss: 1.3835\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9607 - loss: 1.0745 - val_accuracy: 0.7500 - val_loss: 1.3356\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9291 - loss: 1.0542 - val_accuracy: 0.7500 - val_loss: 1.3015\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9399 - loss: 1.0231 - val_accuracy: 0.7500 - val_loss: 1.2717\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9530 - loss: 0.9553 - val_accuracy: 0.7500 - val_loss: 1.2418\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9500 - loss: 0.9307 - val_accuracy: 0.7308 - val_loss: 1.2128\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9696 - loss: 0.8851 - val_accuracy: 0.7692 - val_loss: 1.1812\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.8644 - val_accuracy: 0.7692 - val_loss: 1.1498\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9641 - loss: 0.8361 - val_accuracy: 0.7500 - val_loss: 1.1163\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9526 - loss: 0.8184 - val_accuracy: 0.7692 - val_loss: 1.0960\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.7982 - val_accuracy: 0.7500 - val_loss: 1.0768\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9683 - loss: 0.7399 - val_accuracy: 0.7500 - val_loss: 1.0609\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9620 - loss: 0.7156 - val_accuracy: 0.7500 - val_loss: 1.0425\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9743 - loss: 0.6838 - val_accuracy: 0.7500 - val_loss: 1.0216\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9664 - loss: 0.6677 - val_accuracy: 0.7500 - val_loss: 1.0021\n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9712 - loss: 0.6534 - val_accuracy: 0.7500 - val_loss: 0.9757\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9501 - loss: 0.6651 - val_accuracy: 0.7500 - val_loss: 0.9605\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.5964 - val_accuracy: 0.7500 - val_loss: 0.9425\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.5822 - val_accuracy: 0.7500 - val_loss: 0.9273\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.5641 - val_accuracy: 0.7500 - val_loss: 0.9182\n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9801 - loss: 0.5380 - val_accuracy: 0.7692 - val_loss: 0.9101\n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.5012 - val_accuracy: 0.7692 - val_loss: 0.8977\n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9750 - loss: 0.5058 - val_accuracy: 0.7500 - val_loss: 0.8841\n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.4682 - val_accuracy: 0.7500 - val_loss: 0.8777\n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9935 - loss: 0.4613 - val_accuracy: 0.7692 - val_loss: 0.8644\n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9742 - loss: 0.4681 - val_accuracy: 0.7692 - val_loss: 0.8570\n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.4395 - val_accuracy: 0.7692 - val_loss: 0.8393\n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.4241 - val_accuracy: 0.7692 - val_loss: 0.8249\n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9766 - loss: 0.4139 - val_accuracy: 0.7692 - val_loss: 0.8248\n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.4065 - val_accuracy: 0.7692 - val_loss: 0.8292\n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.3779 - val_accuracy: 0.7692 - val_loss: 0.8323\n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.3668 - val_accuracy: 0.7500 - val_loss: 0.8337\n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.3568 - val_accuracy: 0.7500 - val_loss: 0.8323\n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.3317 - val_accuracy: 0.7500 - val_loss: 0.8306\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7524 - loss: 0.7999 \n",
      "Hybrid Model Accuracy: 0.7692307829856873\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "def build_hybrid_model(num_text_features, num_audio_features, regularization_rate=0.01):\n",
    "    # Text input branch\n",
    "    text_input = Input(shape=(num_text_features,), name='text_input')\n",
    "    text_hidden = Dense(128, activation='relu', kernel_regularizer=l2(regularization_rate))(text_input)\n",
    "    text_hidden = BatchNormalization()(text_hidden)\n",
    "    text_hidden = Dropout(0.3)(text_hidden)\n",
    "\n",
    "    # Audio input branch\n",
    "    audio_input = Input(shape=(num_audio_features,), name='audio_input')\n",
    "    audio_hidden = Dense(128, activation='relu', kernel_regularizer=l2(regularization_rate))(audio_input)\n",
    "    audio_hidden = BatchNormalization()(audio_hidden)\n",
    "    audio_hidden = Dropout(0.3)(audio_hidden)\n",
    "\n",
    "    # Concatenate both branches\n",
    "    concatenated = Concatenate()([text_hidden, audio_hidden])\n",
    "    concatenated = Dense(64, activation='relu', kernel_regularizer=l2(regularization_rate))(concatenated)\n",
    "    concatenated = Dropout(0.3)(concatenated)\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[text_input, audio_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "model_ehhb = build_hybrid_model(num_text_features=11, num_audio_features=11)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Assume X_train_text, X_train_audio, y_train_combined are prepared\n",
    "# and similarly for X_test_text, X_test_audio, y_test_combined\n",
    "history = model_ehhb.fit(\n",
    "    [X_train_text, X_train_audio],\n",
    "    y_train_combined,\n",
    "    validation_data=([X_test_text, X_test_audio], y_test_combined),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "ehhb_accuracy = model_ehhb.evaluate([X_test_text, X_test_audio], y_test_combined)[1]\n",
    "print(\"Hybrid Model Accuracy:\", ehhb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2SlwIkV7fvn0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nViLzrlEgCNL"
   },
   "source": [
    "# Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVihZczIgJKs",
    "outputId": "f2b1543b-7263-4fad-8e85-8c1464042f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
       "       'sentence_level_similarity_emotion', 'sentence_level_similarity_word',\n",
       "       'exclamation', 'PCA_MFCC_1', 'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4',\n",
       "       'PCA_MFCC_5', 'PCA_MFCC_6', 'PCA_MFCC_7', 'PCA_MFCC_8', 'PCA_W2V_1',\n",
       "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
       "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
       "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
       "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
       "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
       "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
       "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
       "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
       "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
       "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50',\n",
       "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'energy',\n",
       "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
       "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
       "       'mfccs_12', 'mfccs_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen = pd.read_csv('/content/Multimodal-Sentiment-Analysis-with-Sarcasm-Detection/datasets/sentiment_final.csv')\n",
    "df_sen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oTjN5HIIbAmt"
   },
   "outputs": [],
   "source": [
    "# Define all the feature columns (text + audio features)\n",
    "all_feature_columns = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of text features for the text-only model\n",
    "feature_columns_text = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of audio features for the text-only model\n",
    "feature_columns_audio = [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VPWv-BGdbB27"
   },
   "outputs": [],
   "source": [
    "# target prediction\n",
    "target_column = 'sentiment_label'\n",
    "\n",
    "# Prepare the feature set and target column for both models\n",
    "X_all = df_sen[all_feature_columns]\n",
    "y = df_sen[target_column]\n",
    "\n",
    "# Function to scale, split, and apply SMOTE\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BLiwRcv5bV1T"
   },
   "outputs": [],
   "source": [
    "# --- Combined Model (Text + Audio Features) ---\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L7nfir-CbBuH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_FCNN_new = load_model(\"model_FCNN.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC4JJRxGpgip"
   },
   "source": [
    "## XG Boost without integrating Sarcasm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xLNqwhulKue",
    "outputId": "70d05864-491b-488f-85eb-193feb461310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.5428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create XGBoost DMatrix\n",
    "dtrain = xgb.DMatrix(X_train_combined, label=y_train_combined)\n",
    "dtest = xgb.DMatrix(X_test_combined, label=y_test_combined)\n",
    "\n",
    "# Set parameters\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 5,\n",
    "    \"n_estimators\": 10,\n",
    "    \"eta\": 0.1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model_xgb = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions\n",
    "preds = model_xgb.predict(dtest)\n",
    "predictions = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test_combined, predictions)\n",
    "print(f\"XGBoost Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iw-6Exnfj-k",
    "outputId": "da59ba77-b76c-47a6-920a-a1f0dcf26ef7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:36] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:38] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost Accuracy: 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_combined)\n",
    "\n",
    "accuracy = accuracy_score(y_test_combined, y_pred)\n",
    "print(f\"Optimized XGBoost Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep1HKF9rpiD4"
   },
   "source": [
    "## XG Boost with Sarcasm Model Integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDvfNbjcnIiv",
    "outputId": "dade2107-a400-497c-e81e-bcdf3c6f6f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated XGBoost Model with Sarcasm Accuracy: 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:30:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
    "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
    "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
    "# Add sarcasm predictions as a new feature\n",
    "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
    "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
    "\n",
    "dtrain = xgb.DMatrix(features_with_sarcasm_train, label=y_train_combined)\n",
    "dtest = xgb.DMatrix(features_with_sarcasm_test, label=y_test_combined)\n",
    "\n",
    "model_xgb_sarcasm = xgb.train(params, dtrain, num_boost_round=100)\n",
    "preds = model_xgb_sarcasm.predict(dtest)\n",
    "predictions = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "accuracy = accuracy_score(y_test_combined, predictions)\n",
    "print(f\"Updated XGBoost Model with Sarcasm Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd4cbC-dpsqX"
   },
   "source": [
    "## FFNN without Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGzO9nFLo7kJ",
    "outputId": "9acd0f5b-7028-4800-b722-9f754315332c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4331 - loss: 0.8909 - val_accuracy: 0.7188 - val_loss: 0.6463\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5283 - loss: 0.7803 - val_accuracy: 0.6250 - val_loss: 0.6629\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4800 - loss: 0.8008 - val_accuracy: 0.5938 - val_loss: 0.6822\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4814 - loss: 0.7425 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6555 - loss: 0.6299 - val_accuracy: 0.4375 - val_loss: 0.6928\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6791 - loss: 0.6430 - val_accuracy: 0.4375 - val_loss: 0.6929\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 0.7136 - val_accuracy: 0.4375 - val_loss: 0.7052\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5362 - loss: 0.6989 - val_accuracy: 0.4062 - val_loss: 0.7111\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.6686 - val_accuracy: 0.3750 - val_loss: 0.7179\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5769 - loss: 0.6470 - val_accuracy: 0.3125 - val_loss: 0.7168\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.6471 - val_accuracy: 0.3125 - val_loss: 0.7125\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4988 - loss: 0.6584 - val_accuracy: 0.3125 - val_loss: 0.6984\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5973 - loss: 0.6673 - val_accuracy: 0.3438 - val_loss: 0.6878\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5845 - loss: 0.6020 - val_accuracy: 0.3125 - val_loss: 0.6882\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6290 - loss: 0.5870 - val_accuracy: 0.3125 - val_loss: 0.6895\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.6443 - val_accuracy: 0.3125 - val_loss: 0.6875\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5767 - loss: 0.6095 - val_accuracy: 0.3125 - val_loss: 0.6877\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 0.6307 - val_accuracy: 0.3125 - val_loss: 0.6861\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6466 - loss: 0.5932 - val_accuracy: 0.3438 - val_loss: 0.6851\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6690 - loss: 0.6020 - val_accuracy: 0.3438 - val_loss: 0.6770\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.5632 - val_accuracy: 0.4375 - val_loss: 0.6664\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.5798 - val_accuracy: 0.5000 - val_loss: 0.6581\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6187 - loss: 0.6403 - val_accuracy: 0.5312 - val_loss: 0.6479\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.5912 - val_accuracy: 0.5938 - val_loss: 0.6406\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 0.6469 - val_accuracy: 0.6250 - val_loss: 0.6411\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.5665 - val_accuracy: 0.6250 - val_loss: 0.6422\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.5473 - val_accuracy: 0.7188 - val_loss: 0.6300\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6579 - loss: 0.5708 - val_accuracy: 0.7812 - val_loss: 0.6254\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7047 - loss: 0.5662 - val_accuracy: 0.8125 - val_loss: 0.6189\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 0.5588 - val_accuracy: 0.8125 - val_loss: 0.6171\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6943 - loss: 0.5249 - val_accuracy: 0.8125 - val_loss: 0.6132\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6774 - loss: 0.5388 - val_accuracy: 0.7812 - val_loss: 0.6137\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.5619 - val_accuracy: 0.7812 - val_loss: 0.6218\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.5434 - val_accuracy: 0.7500 - val_loss: 0.6200\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.4784 - val_accuracy: 0.7500 - val_loss: 0.6194\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.5189 - val_accuracy: 0.7500 - val_loss: 0.6205\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5527 - val_accuracy: 0.7812 - val_loss: 0.6093\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6840 - loss: 0.5015 - val_accuracy: 0.7812 - val_loss: 0.6034\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.5128 - val_accuracy: 0.7812 - val_loss: 0.5951\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.5429 - val_accuracy: 0.7812 - val_loss: 0.5879\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4979 - val_accuracy: 0.7812 - val_loss: 0.5783\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4710 - val_accuracy: 0.7812 - val_loss: 0.5786\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 0.4632 - val_accuracy: 0.8125 - val_loss: 0.5643\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.5377 - val_accuracy: 0.8125 - val_loss: 0.5596\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.5012 - val_accuracy: 0.8125 - val_loss: 0.5523\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6638 - loss: 0.5166 - val_accuracy: 0.8438 - val_loss: 0.5505\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6738 - loss: 0.5440 - val_accuracy: 0.8125 - val_loss: 0.5633\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4436 - val_accuracy: 0.7812 - val_loss: 0.5690\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.4826 - val_accuracy: 0.8125 - val_loss: 0.5705\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.5119 - val_accuracy: 0.8125 - val_loss: 0.5672\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4790 - val_accuracy: 0.8125 - val_loss: 0.5635\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.4645 - val_accuracy: 0.8125 - val_loss: 0.5602\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.4508 - val_accuracy: 0.8438 - val_loss: 0.5535\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.3974 - val_accuracy: 0.8438 - val_loss: 0.5421\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.4541 - val_accuracy: 0.8438 - val_loss: 0.5332\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.4389 - val_accuracy: 0.8438 - val_loss: 0.5227\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4803 - val_accuracy: 0.8438 - val_loss: 0.5177\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.4835 - val_accuracy: 0.8438 - val_loss: 0.5031\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.4237 - val_accuracy: 0.8438 - val_loss: 0.4919\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3768 - val_accuracy: 0.8438 - val_loss: 0.4916\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.4597 - val_accuracy: 0.8438 - val_loss: 0.5053\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.3984 - val_accuracy: 0.8438 - val_loss: 0.4958\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.5349 - val_accuracy: 0.8438 - val_loss: 0.4954\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4458 - val_accuracy: 0.8438 - val_loss: 0.4856\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.4391 - val_accuracy: 0.8438 - val_loss: 0.4809\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.4512 - val_accuracy: 0.8438 - val_loss: 0.4796\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.4956 - val_accuracy: 0.8438 - val_loss: 0.4799\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4150 - val_accuracy: 0.8438 - val_loss: 0.4727\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.3834 - val_accuracy: 0.8438 - val_loss: 0.4598\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.4176 - val_accuracy: 0.8438 - val_loss: 0.4681\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.3463 - val_accuracy: 0.8438 - val_loss: 0.4618\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.4057 - val_accuracy: 0.8438 - val_loss: 0.4620\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8035 - loss: 0.4117 - val_accuracy: 0.8438 - val_loss: 0.4633\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.3554 - val_accuracy: 0.8125 - val_loss: 0.4521\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.3503 - val_accuracy: 0.8125 - val_loss: 0.4518\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.4361 - val_accuracy: 0.8125 - val_loss: 0.4588\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4129 - val_accuracy: 0.8125 - val_loss: 0.4418\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8774 - loss: 0.3602 - val_accuracy: 0.8125 - val_loss: 0.4373\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7770 - loss: 0.4128 - val_accuracy: 0.8125 - val_loss: 0.4508\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.3293 - val_accuracy: 0.8125 - val_loss: 0.4580\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.3378 - val_accuracy: 0.8438 - val_loss: 0.4664\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9193 - loss: 0.2835 - val_accuracy: 0.8438 - val_loss: 0.4705\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.4143 - val_accuracy: 0.8125 - val_loss: 0.4581\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 0.3773 - val_accuracy: 0.8125 - val_loss: 0.4471\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.3360 - val_accuracy: 0.8125 - val_loss: 0.4505\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.3405 - val_accuracy: 0.8438 - val_loss: 0.4533\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.3221 - val_accuracy: 0.8438 - val_loss: 0.4424\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4081 - val_accuracy: 0.8438 - val_loss: 0.4545\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7796 - loss: 0.3844 - val_accuracy: 0.8438 - val_loss: 0.4652\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3156 - val_accuracy: 0.8125 - val_loss: 0.4623\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.2851 - val_accuracy: 0.8125 - val_loss: 0.4539\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8872 - loss: 0.2929 - val_accuracy: 0.7812 - val_loss: 0.4371\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8619 - loss: 0.2973 - val_accuracy: 0.8125 - val_loss: 0.4320\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.3257 - val_accuracy: 0.7812 - val_loss: 0.4290\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.2394 - val_accuracy: 0.7812 - val_loss: 0.4218\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3415 - val_accuracy: 0.7812 - val_loss: 0.4399\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3295 - val_accuracy: 0.7812 - val_loss: 0.4301\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2441 - val_accuracy: 0.7812 - val_loss: 0.4207\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3021 - val_accuracy: 0.7812 - val_loss: 0.4193\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8370 - loss: 0.3105 - val_accuracy: 0.7812 - val_loss: 0.4237\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.9741 \n",
      "FNN Model Accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "model_fnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_train_combined.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_fnn.fit(X_train_combined, y_train_combined, epochs=100, batch_size=5, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_fnn.evaluate(X_test_combined, y_test_combined)\n",
    "print(f\"FNN Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiHTR4mArbte"
   },
   "source": [
    "## FFNN with Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwLrgMnNrOxl",
    "outputId": "806cb4f8-251d-453a-b399-35005d1d77f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4370 - loss: 1.0319 - val_accuracy: 0.5938 - val_loss: 0.6867\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5217 - loss: 0.8853 - val_accuracy: 0.4375 - val_loss: 0.7129\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.7275 - val_accuracy: 0.4062 - val_loss: 0.7257\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4869 - loss: 0.9043 - val_accuracy: 0.3438 - val_loss: 0.7262\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5553 - loss: 0.8006 - val_accuracy: 0.3750 - val_loss: 0.7214\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6179 - loss: 0.6462 - val_accuracy: 0.5312 - val_loss: 0.7093\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.7464 - val_accuracy: 0.4062 - val_loss: 0.7081\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6603 - loss: 0.6175 - val_accuracy: 0.4062 - val_loss: 0.7134\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6462 - loss: 0.5949 - val_accuracy: 0.4062 - val_loss: 0.7029\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6468 - loss: 0.6131 - val_accuracy: 0.3438 - val_loss: 0.7067\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5803 - loss: 0.6767 - val_accuracy: 0.3438 - val_loss: 0.7064\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6078 - loss: 0.6004 - val_accuracy: 0.4688 - val_loss: 0.6915\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5648 - loss: 0.6696 - val_accuracy: 0.5312 - val_loss: 0.6766\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5391 - val_accuracy: 0.5312 - val_loss: 0.6745\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5885 - loss: 0.6557 - val_accuracy: 0.5312 - val_loss: 0.6603\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5841 - loss: 0.6768 - val_accuracy: 0.5312 - val_loss: 0.6561\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6442 - loss: 0.5958 - val_accuracy: 0.5625 - val_loss: 0.6519\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 0.6108 - val_accuracy: 0.5938 - val_loss: 0.6435\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6099 - loss: 0.6055 - val_accuracy: 0.6562 - val_loss: 0.6410\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5582 - loss: 0.6253 - val_accuracy: 0.5625 - val_loss: 0.6415\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6000 - loss: 0.6005 - val_accuracy: 0.5625 - val_loss: 0.6440\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6355 - loss: 0.6137 - val_accuracy: 0.5625 - val_loss: 0.6397\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 0.5958 - val_accuracy: 0.5625 - val_loss: 0.6389\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6691 - loss: 0.6092 - val_accuracy: 0.5625 - val_loss: 0.6388\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.5859 - val_accuracy: 0.5625 - val_loss: 0.6400\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 0.6097 - val_accuracy: 0.6250 - val_loss: 0.6325\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6492 - loss: 0.5985 - val_accuracy: 0.6562 - val_loss: 0.6237\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6690 - loss: 0.5702 - val_accuracy: 0.6562 - val_loss: 0.6149\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6318 - loss: 0.5543 - val_accuracy: 0.6562 - val_loss: 0.6140\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.5841 - val_accuracy: 0.6562 - val_loss: 0.6141\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6574 - loss: 0.5527 - val_accuracy: 0.6250 - val_loss: 0.6085\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.5265 - val_accuracy: 0.6250 - val_loss: 0.6032\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7040 - loss: 0.5740 - val_accuracy: 0.6250 - val_loss: 0.6038\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5561 - val_accuracy: 0.6250 - val_loss: 0.6001\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7176 - loss: 0.5294 - val_accuracy: 0.6250 - val_loss: 0.5995\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6427 - loss: 0.5588 - val_accuracy: 0.6250 - val_loss: 0.6001\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6809 - loss: 0.5656 - val_accuracy: 0.6250 - val_loss: 0.5985\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.4623 - val_accuracy: 0.6250 - val_loss: 0.5950\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7143 - loss: 0.5164 - val_accuracy: 0.6250 - val_loss: 0.5958\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.4953 - val_accuracy: 0.6562 - val_loss: 0.5890\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.4822 - val_accuracy: 0.6562 - val_loss: 0.5845\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.5268 - val_accuracy: 0.6875 - val_loss: 0.5807\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.4360 - val_accuracy: 0.6562 - val_loss: 0.5802\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7158 - loss: 0.4811 - val_accuracy: 0.6250 - val_loss: 0.5882\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.5335 - val_accuracy: 0.6562 - val_loss: 0.5894\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6799 - loss: 0.5012 - val_accuracy: 0.6562 - val_loss: 0.5831\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.4729 - val_accuracy: 0.6875 - val_loss: 0.5749\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.4328 - val_accuracy: 0.6875 - val_loss: 0.5692\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4997 - val_accuracy: 0.6875 - val_loss: 0.5674\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4370 - val_accuracy: 0.6875 - val_loss: 0.5694\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.4448 - val_accuracy: 0.6875 - val_loss: 0.5639\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5078 - val_accuracy: 0.6875 - val_loss: 0.5648\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8248 - loss: 0.4302 - val_accuracy: 0.7188 - val_loss: 0.5616\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4464 - val_accuracy: 0.7188 - val_loss: 0.5677\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.4316 - val_accuracy: 0.7188 - val_loss: 0.5710\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.4695 - val_accuracy: 0.7188 - val_loss: 0.5743\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7363 - loss: 0.4592 - val_accuracy: 0.7188 - val_loss: 0.5781\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7317 - loss: 0.4622 - val_accuracy: 0.7188 - val_loss: 0.5757\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.4643 - val_accuracy: 0.7188 - val_loss: 0.5731\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.4046 - val_accuracy: 0.7500 - val_loss: 0.5639\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4293 - val_accuracy: 0.7500 - val_loss: 0.5615\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.4343 - val_accuracy: 0.7500 - val_loss: 0.5594\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.4218 - val_accuracy: 0.7500 - val_loss: 0.5537\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7232 - loss: 0.4753 - val_accuracy: 0.7500 - val_loss: 0.5596\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.4287 - val_accuracy: 0.7500 - val_loss: 0.5679\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.4967 - val_accuracy: 0.7500 - val_loss: 0.5641\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 0.4000 - val_accuracy: 0.7500 - val_loss: 0.5577\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.4755 - val_accuracy: 0.7500 - val_loss: 0.5549\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4029 - val_accuracy: 0.7500 - val_loss: 0.5558\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4037 - val_accuracy: 0.7500 - val_loss: 0.5472\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.3979 - val_accuracy: 0.7500 - val_loss: 0.5381\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3198 - val_accuracy: 0.7500 - val_loss: 0.5353\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8689 - loss: 0.3286 - val_accuracy: 0.7500 - val_loss: 0.5399\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.3502 - val_accuracy: 0.7500 - val_loss: 0.5298\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.3904 - val_accuracy: 0.7500 - val_loss: 0.5265\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.3807 - val_accuracy: 0.7500 - val_loss: 0.5170\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.4752 - val_accuracy: 0.7500 - val_loss: 0.5315\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.3608 - val_accuracy: 0.7500 - val_loss: 0.5403\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.3264 - val_accuracy: 0.7500 - val_loss: 0.5346\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.4697 - val_accuracy: 0.7500 - val_loss: 0.5354\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.3077 - val_accuracy: 0.7500 - val_loss: 0.5288\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.3504 - val_accuracy: 0.7500 - val_loss: 0.5267\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2741 - val_accuracy: 0.7812 - val_loss: 0.5196\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2582 - val_accuracy: 0.7812 - val_loss: 0.5055\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3343 - val_accuracy: 0.7812 - val_loss: 0.5152\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.3316 - val_accuracy: 0.7812 - val_loss: 0.5254\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.2347 - val_accuracy: 0.7812 - val_loss: 0.5317\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 0.4153 - val_accuracy: 0.7812 - val_loss: 0.5267\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.3836 - val_accuracy: 0.7812 - val_loss: 0.5303\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.3436 - val_accuracy: 0.7812 - val_loss: 0.5410\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.2806 - val_accuracy: 0.7812 - val_loss: 0.5365\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.2673 - val_accuracy: 0.7812 - val_loss: 0.5313\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8836 - loss: 0.3131 - val_accuracy: 0.8125 - val_loss: 0.5352\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3286 - val_accuracy: 0.8125 - val_loss: 0.5301\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.2838 - val_accuracy: 0.7812 - val_loss: 0.5419\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.3204 - val_accuracy: 0.7812 - val_loss: 0.5575\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3211 - val_accuracy: 0.7812 - val_loss: 0.5610\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8494 - loss: 0.2943 - val_accuracy: 0.7812 - val_loss: 0.5706\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2834 - val_accuracy: 0.7812 - val_loss: 0.5737\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3159 - val_accuracy: 0.7812 - val_loss: 0.5713\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5685 - loss: 0.8685\n",
      "FNN Model Accuracy: 0.5714285969734192\n"
     ]
    }
   ],
   "source": [
    "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
    "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
    "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
    "# Add sarcasm predictions as a new feature\n",
    "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
    "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
    "\n",
    "model_fnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(features_with_sarcasm_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_fnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_fnn.fit(features_with_sarcasm_train, y_train_combined, epochs=100, batch_size=5, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_fnn.evaluate(features_with_sarcasm_test, y_test_combined)\n",
    "print(f\"FNN Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzEW1dpCzwvY"
   },
   "source": [
    "## SVM without Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqD91-ZpsarR",
    "outputId": "1a9c3c68-c29f-408c-f778-a2ad5cdbe608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine (SVM) Results:\n",
      "Accuracy: 0.51\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56        20\n",
      "           1       0.44      0.47      0.45        15\n",
      "\n",
      "    accuracy                           0.51        35\n",
      "   macro avg       0.51      0.51      0.51        35\n",
      "weighted avg       0.52      0.51      0.52        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict with SVM\n",
    "y_pred_svm = svm_model.predict(X_test_combined)\n",
    "# Calculate probabilities for SVM\n",
    "y_pred_svm_proba = svm_model.decision_function(X_test_combined)  # For SVM, use decision_function for Precision-Recall\n",
    "\n",
    "\n",
    "# Evaluate SVM Model\n",
    "print(\"\\nSupport Vector Machine (SVM) Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, y_pred_svm):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nN0v3Gg9aHTW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5owhnnrrhXIO"
   },
   "source": [
    "## Create Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIU6wPNFaHij",
    "outputId": "a63e43a2-c4b9-4261-a2e4-475072bc5e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sarcasm_label', 'emotion_label', 'sentiment_label', 'id',\n",
       "       'spectral_centroid', 'spectral_bandwidth', 'pitch', 'PCA_MFCC_1',\n",
       "       'PCA_MFCC_2', 'PCA_MFCC_3', 'PCA_MFCC_4', 'PCA_MFCC_5', 'PCA_MFCC_6',\n",
       "       'PCA_MFCC_7', 'PCA_MFCC_8', 'sentence_level_similarity_emotion',\n",
       "       'sentence_level_similarity_word', 'exclamation', 'PCA_W2V_1',\n",
       "       'PCA_W2V_2', 'PCA_W2V_3', 'PCA_W2V_4', 'PCA_W2V_5', 'PCA_W2V_6',\n",
       "       'PCA_W2V_7', 'PCA_W2V_8', 'PCA_W2V_9', 'PCA_W2V_10', 'PCA_W2V_11',\n",
       "       'PCA_W2V_12', 'PCA_W2V_13', 'PCA_W2V_14', 'PCA_W2V_15', 'PCA_W2V_16',\n",
       "       'PCA_W2V_17', 'PCA_W2V_18', 'PCA_W2V_19', 'PCA_W2V_20', 'PCA_W2V_21',\n",
       "       'PCA_W2V_22', 'PCA_W2V_23', 'PCA_W2V_24', 'PCA_W2V_25', 'PCA_W2V_26',\n",
       "       'PCA_W2V_27', 'PCA_W2V_28', 'PCA_W2V_29', 'PCA_W2V_30', 'PCA_W2V_31',\n",
       "       'PCA_W2V_32', 'PCA_W2V_33', 'PCA_W2V_34', 'PCA_W2V_35', 'PCA_W2V_36',\n",
       "       'PCA_W2V_37', 'PCA_W2V_38', 'PCA_W2V_39', 'PCA_W2V_40', 'PCA_W2V_41',\n",
       "       'PCA_W2V_42', 'PCA_W2V_43', 'PCA_W2V_44', 'PCA_W2V_45', 'PCA_W2V_46',\n",
       "       'PCA_W2V_47', 'PCA_W2V_48', 'PCA_W2V_49', 'PCA_W2V_50', 'PCA_W2V_51',\n",
       "       'PCA_W2V_52', 'PCA_W2V_53', 'PCA_W2V_54', 'PCA_W2V_55', 'PCA_W2V_56',\n",
       "       'PCA_W2V_57', 'PCA_W2V_58', 'PCA_W2V_59', 'PCA_W2V_60', 'energy',\n",
       "       'loudness', 'mfccs_1', 'mfccs_2', 'mfccs_3', 'mfccs_4', 'mfccs_5',\n",
       "       'mfccs_6', 'mfccs_7', 'mfccs_8', 'mfccs_9', 'mfccs_10', 'mfccs_11',\n",
       "       'mfccs_12', 'mfccs_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen = pd.read_csv('../datasets/sentiment_final.csv')\n",
    "df_sar = pd.read_csv('../datasets/sarcasm_final.csv')\n",
    "df_comb = pd.concat([df_sar, df_sen], ignore_index=True)\n",
    "\n",
    "df_comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "byn1gxepaHik"
   },
   "outputs": [],
   "source": [
    "# Define all the feature columns (text + audio features)\n",
    "all_feature_columns = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)] + [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of text features for the text-only model\n",
    "feature_columns_text = [\n",
    "    'sentence_level_similarity_emotion', 'sentence_level_similarity_word', 'exclamation'\n",
    "] + [f'PCA_W2V_{i}' for i in range(1, 9)]\n",
    "\n",
    "# Select a subset of audio features for the text-only model\n",
    "feature_columns_audio = [\n",
    "    'spectral_centroid', 'spectral_bandwidth', 'pitch'\n",
    "] + [f'PCA_MFCC_{i}' for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MMpIuZNZaHik"
   },
   "outputs": [],
   "source": [
    "# target prediction\n",
    "target_column = 'sarcasm_label'\n",
    "\n",
    "# Prepare the feature set and target column for both models\n",
    "X_all = df_comb[all_feature_columns]\n",
    "y = df_comb[target_column]\n",
    "\n",
    "# Function to scale, split, and apply SMOTE\n",
    "def preprocess_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test\n",
    "\n",
    "# --- Text-Only Model ---\n",
    "X_text = df_comb[feature_columns_text]\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = preprocess_data(X_text, y)\n",
    "\n",
    "# --- Audio-Only Model --- this is for following hybrid model\n",
    "X_audio = df_comb[feature_columns_audio]\n",
    "X_train_audio, X_test_audio, y_train_audio, y_test_audio = preprocess_data(X_audio, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3HolBhH7kK4y"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Combined Model (Text + Audio Features) ---\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = preprocess_data(X_all, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-BVTX0TpiuQ"
   },
   "source": [
    "## Sentiment Model with Deep Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1Q4nUR2z0sP",
    "outputId": "04a64d89-32ab-4df5-a46d-4077da3720ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5828 - loss: 0.6689 - val_accuracy: 0.7674 - val_loss: 0.5526\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.5065 - val_accuracy: 0.7674 - val_loss: 0.4734\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.4381 - val_accuracy: 0.8256 - val_loss: 0.4395\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3918 - val_accuracy: 0.8488 - val_loss: 0.4255\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.3557 - val_accuracy: 0.8488 - val_loss: 0.4100\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.3198 - val_accuracy: 0.8372 - val_loss: 0.4020\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2950 - val_accuracy: 0.8372 - val_loss: 0.4042\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2771 - val_accuracy: 0.8488 - val_loss: 0.4077\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9028 - loss: 0.2538 - val_accuracy: 0.8372 - val_loss: 0.4070\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9259 - loss: 0.2304 - val_accuracy: 0.8372 - val_loss: 0.4128\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3964 \n",
      "Test Accuracy: 83.72%\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89        66\n",
      "           1       0.64      0.70      0.67        20\n",
      "\n",
      "    accuracy                           0.84        86\n",
      "   macro avg       0.77      0.79      0.78        86\n",
      "weighted avg       0.84      0.84      0.84        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_model(max_length, audio_feature_length, binary=True):\n",
    "    text_input = tf.keras.layers.Input(shape=(max_length,), name='text_input')\n",
    "    text_output = tf.keras.layers.Dense(128, activation='relu')(text_input)\n",
    "\n",
    "    audio_input = tf.keras.layers.Input(shape=(audio_feature_length,), name='audio_input')\n",
    "    audio_output = tf.keras.layers.Dense(128, activation='relu')(audio_input)\n",
    "\n",
    "    combined = tf.keras.layers.concatenate([text_output, audio_output])\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(combined)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    if binary:\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        output = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=[text_input, audio_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model for binary classification\n",
    "model = create_model(max_length=X_train_text.shape[1], audio_feature_length=X_train_audio.shape[1], binary=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    [X_train_text, X_train_audio], y_train_text,\n",
    "    validation_data=([X_test_text, X_test_audio], y_test_text),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate([X_test_text, X_test_audio], y_test_text)\n",
    "print(f\"Test Accuracy: {results[1]*100:.2f}%\")\n",
    "\n",
    "predicted_probs = model.predict([X_test_text, X_test_audio])\n",
    "predicted_labels = (predicted_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, predicted_labels):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCSdzchtpsMN"
   },
   "source": [
    "## Sentiment Model with Deep Neural Network + Sarcasm as feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PsO0LSrzpqsk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmSO_61DYR5I",
    "outputId": "597171a2-020a-49e6-90d6-d8dd6c4fc3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5525 - loss: 0.7120\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7682 - loss: 0.5112 \n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.4267\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3735 \n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3214 \n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.3025 \n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2663 \n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2214\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.2073\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9318 - loss: 0.2043 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.2927  \n",
      "Test Accuracy: 88.37%\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        66\n",
      "           1       0.69      0.90      0.78        20\n",
      "\n",
      "    accuracy                           0.88        86\n",
      "   macro avg       0.83      0.89      0.85        86\n",
      "weighted avg       0.90      0.88      0.89        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assume `sarcasm_model` is a trained sarcasm detection model\n",
    "sarcasm_predictions_train = clf_model.predict(X_train_combined)  # Generate sarcasm labels (0 or 1)\n",
    "sarcasm_predictions_test = clf_model.predict(X_test_combined)  # Generate sarcasm labels (0 or 1)\n",
    "# Add sarcasm predictions as a new feature\n",
    "features_with_sarcasm_train = np.hstack((X_train_combined, sarcasm_predictions_train.reshape(-1, 1)))\n",
    "features_with_sarcasm_test = np.hstack((X_test_combined, sarcasm_predictions_test.reshape(-1, 1)))\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_model(feature_length, binary=True):\n",
    "    # Input layer to accommodate text, audio, and sarcasm features\n",
    "    inputs = tf.keras.layers.Input(shape=(feature_length,), name='combined_input')\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Output layer configuration based on binary or categorical\n",
    "    if binary:\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Determine the feature length based on your new combined datasets\n",
    "feature_length = features_with_sarcasm_train.shape[1]\n",
    "\n",
    "# Create the model\n",
    "model = create_model(feature_length, binary=True)\n",
    "\n",
    "# Fit the model using the enhanced datasets\n",
    "history = model.fit(\n",
    "    features_with_sarcasm_train, y_train_text,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(features_with_sarcasm_test, y_test_text)\n",
    "print(f\"Test Accuracy: {results[1]*100:.2f}%\")\n",
    "\n",
    "predicted_probs = model.predict(features_with_sarcasm_test)\n",
    "predicted_labels = (predicted_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_combined, predicted_labels):.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_combined, predicted_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QketZmjmpxic"
   },
   "source": [
    "## Sentiment Model with Deep Neural Network + Sarcasm Sentiment Set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGzKagSWpJoC",
    "outputId": "4d9d4d92-0b46-4729-ad69-303e842e4f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 0.73\n",
      "Adjusted Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.85        66\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.73        86\n",
      "   macro avg       0.38      0.48      0.42        86\n",
      "weighted avg       0.58      0.73      0.65        86\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      " [[63  3]\n",
      " [20  0]]\n"
     ]
    }
   ],
   "source": [
    "final_predicted_labels = np.where(sarcasm_predictions_test == 1, 0, predicted_labels)\n",
    "\n",
    "# Calculate accuracy and other metrics after adjusting for sarcasm\n",
    "print(f\"Adjusted Accuracy: {accuracy_score(y_test_text, final_predicted_labels):.2f}\")\n",
    "print(\"Adjusted Classification Report:\\n\", classification_report(y_test_text, final_predicted_labels))\n",
    "print(\"Adjusted Confusion Matrix:\\n\", confusion_matrix(y_test_text, final_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIl-c-YjrGng"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
